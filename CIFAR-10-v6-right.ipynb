{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youcancallme/sdu-deeplearning-cifar-10/blob/main/CIFAR-10-v6-right.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDkwnu6X4el-"
      },
      "source": [
        "# 初始化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDKs8U2z4el_"
      },
      "source": [
        "## 本地实现"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuPONzSXfdg1"
      },
      "source": [
        "首先进行的是文件读取"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j01-fgRTfjeR",
        "outputId": "5e22cf7f-603a-4b3e-8b09-b8246c8b06ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkP6KD4j4emC"
      },
      "source": [
        "## torchvision实现"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KumQxCz64emC"
      },
      "source": [
        "上面是我自己对数据的处理，其实torchvision提供了对cifar-10数据集的处理，并且提供了及其方便的预处理代码"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cmu5X4aM4emD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6MeWu1R4emD"
      },
      "source": [
        "### 数据增强"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIj2nYmM4emD"
      },
      "source": [
        "图像增广，训练集进行增广，测试时标准化执行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Sw16QZnV4emD"
      },
      "outputs": [],
      "source": [
        "#已经解压的数据集路径\n",
        "#本地\n",
        "# unzip_folder_path='../cifar-10-python'\n",
        "#colab\n",
        "unzip_folder_path= '/content/drive/MyDrive/cifar-10-python'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1c7rN2oL4emD"
      },
      "outputs": [],
      "source": [
        "#训练集\n",
        "transform_train = torchvision.transforms.Compose([\n",
        "    # 在高度和宽度上将图像放大到40像素的正方形\n",
        "    torchvision.transforms.Resize(40),\n",
        "    # 生成一个面积为原始图像面积0.64～1倍的小正方形，\n",
        "    # 然后将其缩放为高度和宽度均为32像素的正方形\n",
        "    torchvision.transforms.RandomResizedCrop(32, scale=(0.64, 1.0),ratio=(1.0, 1.0)),\n",
        "    #以 50% 的概率对输入图像进行水平翻转,用于数据增强。\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    # NumPy 数组转换为 PyTorch Tensor 。\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    # 标准化图像的每个通道 三通道分别归一化，到均值为 0、标准差为 1 的分布。\n",
        "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
        "                                     [0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "#测试集\n",
        "transform_test = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
        "                                     [0.2023, 0.1994, 0.2010])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xymu_dC04emD"
      },
      "outputs": [],
      "source": [
        "#如果不使用数据增广的话，只将数据变为tensor和标准化\n",
        "transform= torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
        "                                     [0.2023, 0.1994, 0.2010])])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cJxK43n64emD"
      },
      "outputs": [],
      "source": [
        "#训练集 train=True加载训练集\n",
        "trainset = torchvision.datasets.CIFAR10(root=unzip_folder_path, train=True,\n",
        "                                        download=False, transform=transform_train)\n",
        "\n",
        "#测试集\n",
        "testset = torchvision.datasets.CIFAR10(root=unzip_folder_path, train=False,\n",
        "                                       download=False, transform=transform_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DIW8SNS_C7H",
        "outputId": "74a734e9-1072-4606-db22-9b7b0b2b24dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "image, label = trainset[0]\n",
        "image_size = image.size()\n",
        "image_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6oZQvPX4emD"
      },
      "source": [
        "### 创建数据加载器"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elzBKu_w4emD"
      },
      "source": [
        "DataLoader将数据集转换为可迭代的数据加载器对象。\n",
        "batch_size参数指定每个批次中的样本数量。\n",
        "shuffle=True表示在每个时期(epoch)开始时对数据进行洗牌。\n",
        "num_workers参数指定用于数据加载的线程数\n",
        "但是这里没用到啊，只有在kfold哪里用到了，而且test的还没有进行验证"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ff_mSOxK4emE"
      },
      "outputs": [],
      "source": [
        "# #训练集  batch_size=128  shuffle=True打乱数据  num_workers=2使用两个进程加载数据\n",
        "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "#                                           shuffle=True, num_workers=2)\n",
        "\n",
        "# #测试集 batch_size=128  shuffle=False不打乱数据  num_workers=2使用两个进程加载数据\n",
        "# testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "#                                          shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7aMuYZH4emE"
      },
      "source": [
        "## 1折交叉验证"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCXrvNlI4emE"
      },
      "source": [
        "使用KFold类从sklearn.model_selection库中创建了一个1折交叉验证对象。n_splits参数设置为10，表示将数据集划分为10个折（10份），shuffle=True表示在划分前对数据进行洗牌。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Et9cwLFF4emE"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=10, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AcZ0r2nq4emE"
      },
      "outputs": [],
      "source": [
        "# argmax 函数别名定义了一个匿名函数，它接受参数 x，并调用 x.argmax(*args, **kwargs) 方法。\n",
        "# astype 函数别名定义了一个匿名函数，它接受参数 x，并调用 x.type(*args, **kwargs) 方法。\n",
        "# reduce_sum 函数别名定义了一个匿名函数，它接受参数 x，并调用 x.sum(*args, **kwargs) 方法。\n",
        "\n",
        "argmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs)\n",
        "astype = lambda x, *args, **kwargs: x.type(*args, **kwargs)\n",
        "reduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)\n",
        "def accuracy(y_hat, y):\n",
        "    #首先处理y_hat形状，如果 y_hat 的维度大于1且最后一个维度大于1,则说明 y_hat 是一个包含多个类别概率的tensor。\n",
        "    #这种情况下,需要使用 argmax 函数找出每个样本预测概率最高的类别索引,赋值给 y_hat。\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = argmax(y_hat, axis=1)\n",
        "  #使用astype函数将y_hat的数据类型转换为和y相同的类型,方便比较\n",
        "  #比较是否相等，如果相等就得到布尔类型的tensor\n",
        "    cmp = astype(y_hat, y.dtype) == y\n",
        "  #使用 reduce_sum 函数统计 cmp 中为True的元素个数,得到预测正确的样本数\n",
        "    return float(reduce_sum(astype(cmp, y.dtype)))\n",
        "# def accuracy(y_hat, y):\n",
        "#     \"\"\"Compute the number of correct predictions.\"\"\"\n",
        "#     if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "#         y_hat = y_hat.argmax(dim=1)\n",
        "#     cmp = y_hat.type(y.dtype) == y\n",
        "#     return float(cmp.type(y.dtype).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "U5Pzk1fA4emE"
      },
      "outputs": [],
      "source": [
        "def train_batch(net, X, y, loss, trainer, devices):\n",
        "    # 转移到一个device上\n",
        "    if isinstance(X, list):\n",
        "        # Required for BERT fine-tuning (to be covered later)\n",
        "        X = [x.to(devices[0]) for x in X]\n",
        "    else:\n",
        "        X = X.to(devices[0])\n",
        "    y = y.to(devices[0])\n",
        "    #训练\n",
        "    net.train()\n",
        "    #梯度为0\n",
        "    trainer.zero_grad()\n",
        "    #前向传播\n",
        "    pred = net(X)\n",
        "    #计算损失\n",
        "    l = loss(pred, y)\n",
        "    #反向传播更新参数\n",
        "    l.sum().backward()\n",
        "    trainer.step()\n",
        "\n",
        "    #本批次的损失和准确度\n",
        "    train_loss_sum = l.sum()\n",
        "    train_acc_sum = accuracy(pred, y)\n",
        "    return train_loss_sum, train_acc_sum\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#用于训练：\n",
        "def train(train_iter,valid_iter,net, criterion, lr_period, lr_decay, lr, wd, devices, num_epochs=1, batch_size=128):\n",
        "  # 为每一折创建一个新的网络实例\n",
        "    model = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
        "\n",
        "      # sgd优化器\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
        "    #学习率调度器，\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_period, lr_decay)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "\n",
        "        #running_loss 用于记录整个训练过程中的累积损失值。\n",
        "        running_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        #循环训练集的特征和标签\n",
        "        for i, (inputs, labels) in enumerate(train_iter):\n",
        "          #计算每个批次的损失和返回预测正确的样本数，\n",
        "          #net 特征 标签 损失函数 sgd优化器 设备\n",
        "            loss, acc = train_batch(model, inputs, labels, criterion, optimizer, devices)\n",
        "            #用正确的样本数/当前batch的总样本数即可\n",
        "            Acc=float(acc) / labels.shape[0]\n",
        "\n",
        "          #将当前批次的损失值 loss 加到 running_loss 变量中。\n",
        "            running_loss += loss.item()\n",
        "          #检查当前批次的索引是否为训练数据批次总数的 1/5 倍,或者是否为最后一个批次。\n",
        "            if (i + 1) % (len(train_iter) // 5) == 0 or i == len(train_iter) - 1:\n",
        "              #当前batch的索引和总batch数量，当前的平均损失，当前的准确率\n",
        "                print(f'Epoch [{epoch+1}/{num_epochs}]，Batch [{i+1}/{len(train_iter)}], Loss: {running_loss / (i + 1):.4f}, Acc: {Acc:.2f}')\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "    # with torch.no_grad():\n",
        "    if valid_iter is not None:\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in valid_iter:\n",
        "            inputs = inputs.to(devices[0])\n",
        "            labels = labels.to(devices[0])\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Validation Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CG1-AGv1H1gS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#可以用于验证集测试\n",
        "def k_fold(net, criterion, lr_period, lr_decay, lr, wd, trainset,devices, num_epochs=1, batch_size=128):\n",
        "    # 使用 KFold 进行 10 折交叉验证，shuffle=True 表示打乱数据集\n",
        "    kfold = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "    # for epoch in range(num_epochs):\n",
        "        # 一折交叉验证\n",
        "    for fold, (train_indices, val_indices) in enumerate(kfold.split(trainset)):\n",
        "        print(f'Fold {fold+1}')\n",
        "        trainset_fold = torch.utils.data.Subset(trainset, train_indices)  # 获取当前折的训练集\n",
        "        valset_fold = torch.utils.data.Subset(trainset, val_indices)  # 获取当前折的验证集\n",
        "\n",
        "        #当前折训练数据集\n",
        "        trainloader_fold = torch.utils.data.DataLoader(trainset_fold, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "        #当前折验证数据集\n",
        "        valloader_fold = torch.utils.data.DataLoader(valset_fold, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "        train (trainloader_fold, valloader_fold,net, criterion, lr_period, lr_decay, lr, wd, devices)\n",
        "\n"
      ],
      "metadata": {
        "id": "LQdtxymQHmOd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2swg6sg4emE"
      },
      "source": [
        "## ResNet模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc_FCUk-4emF"
      },
      "source": [
        "残差块"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wuZxJ8Zq4emF"
      },
      "outputs": [],
      "source": [
        "from torch.nn import functional as F\n",
        "#画图表示\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, input_channels, num_channels,\n",
        "                 use_1x1conv=False, strides=1):\n",
        "        #初始化\n",
        "        super().__init__()\n",
        "        #两个卷积层，内核大小都为3，\n",
        "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
        "                               kernel_size=3, padding=1, stride=strides)\n",
        "        #输入通道为上一层的输出通道\n",
        "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
        "                               kernel_size=3, padding=1)\n",
        "        if use_1x1conv:#如果不使用的话，在应用Relu前，将输入添加到输出；如果使用，通过添加1×1卷积来调整通道和分辨率\n",
        "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
        "                                   kernel_size=1, stride=strides)\n",
        "        else:\n",
        "            self.conv3 = None\n",
        "        #两个批量归一化层\n",
        "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "        if self.conv3:\n",
        "            X = self.conv3(X)\n",
        "        Y += X\n",
        "        return F.relu(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-5i_NbFU4emF"
      },
      "outputs": [],
      "source": [
        "def resnet18(num_classes, in_channels=1):\n",
        "\n",
        "    def resnet_block(in_channels, out_channels, num_residuals,\n",
        "                     first_block=False):\n",
        "        blk = []\n",
        "        for i in range(num_residuals):\n",
        "            if i == 0 and not first_block:\n",
        "                blk.append(\n",
        "                    Residual(in_channels, out_channels, use_1x1conv=True,\n",
        "                                 strides=2))\n",
        "            else:\n",
        "                blk.append(Residual(out_channels, out_channels))\n",
        "        return nn.Sequential(*blk)\n",
        "\n",
        "    # This model uses a smaller convolution kernel, stride, and padding and\n",
        "    #不可以删掉最大池化层，可能会使梯度消失，使网络的感受野减小\n",
        "    net = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(64), nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "    net.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\n",
        "    net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\n",
        "    net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\n",
        "    net.add_module(\"resnet_block4\", resnet_block(256, 512, 2))\n",
        "    net.add_module(\"global_avg_pool\", nn.AdaptiveAvgPool2d((1, 1)))\n",
        "    net.add_module(\"fc\",\n",
        "                   nn.Sequential(nn.Flatten(), nn.Linear(512, num_classes)))\n",
        "    return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "giWmXSrU4emF"
      },
      "outputs": [],
      "source": [
        "def get_net():\n",
        "    num_classes = 10\n",
        "    net = resnet18(num_classes, 3)\n",
        "    return net\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(reduction=\"none\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-anj7-7q_C7J",
        "outputId": "8df2142e-6223-4449-9207-f81c371513c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d output shape:\t torch.Size([4, 64, 32, 32])\n",
            "BatchNorm2d output shape:\t torch.Size([4, 64, 32, 32])\n",
            "ReLU output shape:\t torch.Size([4, 64, 32, 32])\n",
            "MaxPool2d output shape:\t torch.Size([4, 64, 16, 16])\n",
            "Sequential output shape:\t torch.Size([4, 64, 16, 16])\n",
            "Sequential output shape:\t torch.Size([4, 128, 8, 8])\n",
            "Sequential output shape:\t torch.Size([4, 256, 4, 4])\n",
            "Sequential output shape:\t torch.Size([4, 512, 2, 2])\n",
            "AdaptiveAvgPool2d output shape:\t torch.Size([4, 512, 1, 1])\n",
            "Sequential output shape:\t torch.Size([4, 10])\n"
          ]
        }
      ],
      "source": [
        "X = torch.rand(size=(4, 3, 32, 32))\n",
        "net=get_net()\n",
        "for layer in net:\n",
        "    X = layer(X)\n",
        "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyIvt_FKD0IZ",
        "outputId": "1bc896cb-6899-4c39-81db-b0c0ea401485"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "swb4MIRTD0sy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KoJKIujw6YOS"
      },
      "outputs": [],
      "source": [
        "def try_all_gpus():\n",
        "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\"\"\"\n",
        "    devices = [\n",
        "        torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
        "    return devices if devices else [torch.device('cpu')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR7u-fHK4emF",
        "outputId": "452de771-1342-4c62-ad50-69ac45ecf369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "Epoch [1/1]，Batch [70/352], Loss: 243.7862, Acc: 0.43\n",
            "Epoch [1/1]，Batch [140/352], Loss: 220.9874, Acc: 0.43\n",
            "Epoch [1/1]，Batch [210/352], Loss: 210.4383, Acc: 0.55\n",
            "Epoch [1/1]，Batch [280/352], Loss: 200.9497, Acc: 0.52\n",
            "Epoch [1/1]，Batch [350/352], Loss: 193.2528, Acc: 0.56\n",
            "Epoch [1/1]，Batch [352/352], Loss: 192.9018, Acc: 0.51\n",
            "Validation Accuracy: 52.70%\n",
            "Fold 2\n",
            "Epoch [1/1]，Batch [70/352], Loss: 154.3182, Acc: 0.59\n",
            "Epoch [1/1]，Batch [140/352], Loss: 148.9964, Acc: 0.51\n",
            "Epoch [1/1]，Batch [210/352], Loss: 147.5348, Acc: 0.66\n",
            "Epoch [1/1]，Batch [280/352], Loss: 145.2591, Acc: 0.62\n",
            "Epoch [1/1]，Batch [350/352], Loss: 142.8232, Acc: 0.62\n",
            "Epoch [1/1]，Batch [352/352], Loss: 142.5227, Acc: 0.71\n",
            "Validation Accuracy: 62.34%\n",
            "Fold 3\n",
            "Epoch [1/1]，Batch [70/352], Loss: 122.8655, Acc: 0.65\n",
            "Epoch [1/1]，Batch [140/352], Loss: 122.2723, Acc: 0.63\n",
            "Epoch [1/1]，Batch [210/352], Loss: 121.4547, Acc: 0.80\n",
            "Epoch [1/1]，Batch [280/352], Loss: 120.7772, Acc: 0.73\n",
            "Epoch [1/1]，Batch [350/352], Loss: 118.6129, Acc: 0.77\n",
            "Epoch [1/1]，Batch [352/352], Loss: 118.4021, Acc: 0.78\n",
            "Validation Accuracy: 70.76%\n",
            "Fold 4\n",
            "Epoch [1/1]，Batch [70/352], Loss: 100.7911, Acc: 0.69\n",
            "Epoch [1/1]，Batch [140/352], Loss: 102.8945, Acc: 0.64\n",
            "Epoch [1/1]，Batch [210/352], Loss: 102.4545, Acc: 0.73\n",
            "Epoch [1/1]，Batch [280/352], Loss: 102.2051, Acc: 0.72\n",
            "Epoch [1/1]，Batch [350/352], Loss: 101.6984, Acc: 0.73\n",
            "Epoch [1/1]，Batch [352/352], Loss: 101.6345, Acc: 0.68\n",
            "Validation Accuracy: 72.70%\n",
            "Fold 5\n",
            "Epoch [1/1]，Batch [70/352], Loss: 92.9935, Acc: 0.72\n",
            "Epoch [1/1]，Batch [140/352], Loss: 94.3344, Acc: 0.72\n",
            "Epoch [1/1]，Batch [210/352], Loss: 92.6462, Acc: 0.76\n",
            "Epoch [1/1]，Batch [280/352], Loss: 91.6269, Acc: 0.76\n",
            "Epoch [1/1]，Batch [350/352], Loss: 90.8731, Acc: 0.77\n",
            "Epoch [1/1]，Batch [352/352], Loss: 90.8569, Acc: 0.69\n",
            "Validation Accuracy: 76.38%\n",
            "Fold 6\n",
            "Epoch [1/1]，Batch [70/352], Loss: 79.7726, Acc: 0.77\n",
            "Epoch [1/1]，Batch [140/352], Loss: 80.2501, Acc: 0.71\n",
            "Epoch [1/1]，Batch [210/352], Loss: 79.8886, Acc: 0.87\n",
            "Epoch [1/1]，Batch [280/352], Loss: 80.2182, Acc: 0.80\n",
            "Epoch [1/1]，Batch [350/352], Loss: 79.8589, Acc: 0.79\n",
            "Epoch [1/1]，Batch [352/352], Loss: 79.7885, Acc: 0.85\n",
            "Validation Accuracy: 78.12%\n",
            "Fold 7\n",
            "Epoch [1/1]，Batch [70/352], Loss: 70.0351, Acc: 0.80\n",
            "Epoch [1/1]，Batch [140/352], Loss: 70.6238, Acc: 0.79\n",
            "Epoch [1/1]，Batch [210/352], Loss: 71.5956, Acc: 0.81\n",
            "Epoch [1/1]，Batch [280/352], Loss: 71.9782, Acc: 0.71\n",
            "Epoch [1/1]，Batch [350/352], Loss: 72.1211, Acc: 0.80\n",
            "Epoch [1/1]，Batch [352/352], Loss: 72.0423, Acc: 0.75\n",
            "Validation Accuracy: 78.38%\n",
            "Fold 8\n",
            "Epoch [1/1]，Batch [70/352], Loss: 65.8412, Acc: 0.89\n",
            "Epoch [1/1]，Batch [140/352], Loss: 66.4470, Acc: 0.86\n",
            "Epoch [1/1]，Batch [210/352], Loss: 66.6132, Acc: 0.88\n",
            "Epoch [1/1]，Batch [280/352], Loss: 66.9613, Acc: 0.81\n",
            "Epoch [1/1]，Batch [350/352], Loss: 66.9694, Acc: 0.73\n",
            "Epoch [1/1]，Batch [352/352], Loss: 66.8520, Acc: 0.82\n",
            "Validation Accuracy: 80.64%\n",
            "Fold 9\n",
            "Epoch [1/1]，Batch [70/352], Loss: 57.6463, Acc: 0.88\n",
            "Epoch [1/1]，Batch [140/352], Loss: 60.2302, Acc: 0.81\n",
            "Epoch [1/1]，Batch [210/352], Loss: 61.0397, Acc: 0.85\n",
            "Epoch [1/1]，Batch [280/352], Loss: 61.1378, Acc: 0.84\n",
            "Epoch [1/1]，Batch [350/352], Loss: 61.4067, Acc: 0.83\n",
            "Epoch [1/1]，Batch [352/352], Loss: 61.4240, Acc: 0.76\n",
            "Validation Accuracy: 80.12%\n",
            "Fold 10\n",
            "Epoch [1/1]，Batch [70/352], Loss: 56.6022, Acc: 0.78\n",
            "Epoch [1/1]，Batch [140/352], Loss: 57.0118, Acc: 0.81\n",
            "Epoch [1/1]，Batch [210/352], Loss: 57.0475, Acc: 0.83\n",
            "Epoch [1/1]，Batch [280/352], Loss: 57.2698, Acc: 0.85\n",
            "Epoch [1/1]，Batch [350/352], Loss: 57.8128, Acc: 0.84\n",
            "Epoch [1/1]，Batch [352/352], Loss: 57.8125, Acc: 0.83\n",
            "Validation Accuracy: 83.86%\n"
          ]
        }
      ],
      "source": [
        "# 训练：\n",
        "device,num_epochs, lr, wd =try_all_gpus(),20, 2e-4, 5e-4\n",
        "lr_period, lr_decay, net = 4, 0.9, get_net()\n",
        "# train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,lr_decay)\n",
        "k_fold(net, criterion, lr_period, lr_decay, lr, wd, trainset,device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader, devices):\n",
        "    \"\"\"\n",
        "    在完整的验证集上评估模型性能\n",
        "\n",
        "    参数:\n",
        "    model (torch.nn.Module): 训练好的模型\n",
        "    testset (torch.utils.data.Dataset): 验证数据集\n",
        "    device (torch.device): 运行设备(CPU或GPU)\n",
        "\n",
        "    返回:\n",
        "    float: 模型在验证集上的性能指标(例如准确率)\n",
        "    \"\"\"\n",
        "    model = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
        "\n",
        "    model.eval()  # 设置模型为评估模式\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # test_loader = DataLoader(testset, batch_size=128, shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            if isinstance(data, list):\n",
        "              # Required for BERT fine-tuning (to be covered later)\n",
        "              data = [x.to(devices[0]) for x in data]\n",
        "            else:\n",
        "                data = data.to(devices[0])\n",
        "            target =  target.to(devices[0])\n",
        "            output = model(data)\n",
        "\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Validation Accuracy: {accuracy:.2f}%')\n",
        "    # return accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "RE3M5v5ELoUA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# net=get_net()\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=True, num_workers=2)\n",
        "evaluate(net, test_loader, device)"
      ],
      "metadata": {
        "id": "Tc4ELE8HM2wx",
        "outputId": "82ce7ac8-827f-4474-99f9-21775f8caaee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 76.57%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "d2l",
      "language": "python",
      "name": "d2l"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}