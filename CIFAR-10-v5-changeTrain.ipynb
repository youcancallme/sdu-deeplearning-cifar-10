{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youcancallme/sdu-deeplearning-cifar-10/blob/main/CIFAR-10-v4-first.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDkwnu6X4el-"
      },
      "source": [
        "# 初始化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDKs8U2z4el_"
      },
      "source": [
        "## 本地实现"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuPONzSXfdg1"
      },
      "source": [
        "首先进行的是文件读取"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j01-fgRTfjeR",
        "outputId": "bd84c284-8861-47fd-fbae-842115dd5291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkP6KD4j4emC"
      },
      "source": [
        "## torchvision实现"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KumQxCz64emC"
      },
      "source": [
        "上面是我自己对数据的处理，其实torchvision提供了对cifar-10数据集的处理，并且提供了及其方便的预处理代码"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cmu5X4aM4emD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6MeWu1R4emD"
      },
      "source": [
        "### 数据增强"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIj2nYmM4emD"
      },
      "source": [
        "图像增广，训练集进行增广，测试时标准化执行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sw16QZnV4emD"
      },
      "outputs": [],
      "source": [
        "#已经解压的数据集路径\n",
        "#本地\n",
        "unzip_folder_path='../cifar-10-python'\n",
        "#colab\n",
        "# unzip_folder_path= '/content/drive/MyDrive/cifar-10-python'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1c7rN2oL4emD"
      },
      "outputs": [],
      "source": [
        "#训练集\n",
        "transform_train = torchvision.transforms.Compose([\n",
        "    # 在高度和宽度上将图像放大到40像素的正方形\n",
        "    torchvision.transforms.Resize(40),\n",
        "    # 生成一个面积为原始图像面积0.64～1倍的小正方形，\n",
        "    # 然后将其缩放为高度和宽度均为32像素的正方形\n",
        "    torchvision.transforms.RandomResizedCrop(32, scale=(0.64, 1.0),ratio=(1.0, 1.0)),\n",
        "    #以 50% 的概率对输入图像进行水平翻转,用于数据增强。\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    # NumPy 数组转换为 PyTorch Tensor 。\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    # 标准化图像的每个通道 三通道分别归一化，到均值为 0、标准差为 1 的分布。\n",
        "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
        "                                     [0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "#测试集\n",
        "transform_test = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
        "                                     [0.2023, 0.1994, 0.2010])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xymu_dC04emD"
      },
      "outputs": [],
      "source": [
        "#如果不使用数据增广的话，只将数据变为tensor和标准化\n",
        "transform= torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
        "                                     [0.2023, 0.1994, 0.2010])])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cJxK43n64emD"
      },
      "outputs": [],
      "source": [
        "#训练集 train=True加载训练集\n",
        "trainset = torchvision.datasets.CIFAR10(root=unzip_folder_path, train=True,\n",
        "                                        download=False, transform=transform_train)\n",
        "\n",
        "#测试集\n",
        "testset = torchvision.datasets.CIFAR10(root=unzip_folder_path, train=False,\n",
        "                                       download=False, transform=transform_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image, label = trainset[0]\n",
        "image_size = image.size()\n",
        "image_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6oZQvPX4emD"
      },
      "source": [
        "### 创建数据加载器"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elzBKu_w4emD"
      },
      "source": [
        "DataLoader将数据集转换为可迭代的数据加载器对象。\n",
        "batch_size参数指定每个批次中的样本数量。\n",
        "shuffle=True表示在每个时期(epoch)开始时对数据进行洗牌。\n",
        "num_workers参数指定用于数据加载的线程数\n",
        "但是这里没用到啊，只有在kfold哪里用到了，而且test的还没有进行验证"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ff_mSOxK4emE"
      },
      "outputs": [],
      "source": [
        "# #训练集  batch_size=128  shuffle=True打乱数据  num_workers=2使用两个进程加载数据\n",
        "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "#                                           shuffle=True, num_workers=2)\n",
        "\n",
        "# #测试集 batch_size=128  shuffle=False不打乱数据  num_workers=2使用两个进程加载数据\n",
        "# testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "#                                          shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7aMuYZH4emE"
      },
      "source": [
        "## 1折交叉验证"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCXrvNlI4emE"
      },
      "source": [
        "使用KFold类从sklearn.model_selection库中创建了一个1折交叉验证对象。n_splits参数设置为10，表示将数据集划分为10个折（10份），shuffle=True表示在划分前对数据进行洗牌。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Et9cwLFF4emE"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=10, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AcZ0r2nq4emE"
      },
      "outputs": [],
      "source": [
        "# argmax 函数别名定义了一个匿名函数，它接受参数 x，并调用 x.argmax(*args, **kwargs) 方法。\n",
        "# astype 函数别名定义了一个匿名函数，它接受参数 x，并调用 x.type(*args, **kwargs) 方法。\n",
        "# reduce_sum 函数别名定义了一个匿名函数，它接受参数 x，并调用 x.sum(*args, **kwargs) 方法。\n",
        "\n",
        "argmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs)\n",
        "astype = lambda x, *args, **kwargs: x.type(*args, **kwargs)\n",
        "reduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)\n",
        "def accuracy(y_hat, y):\n",
        "    #首先处理y_hat形状，如果 y_hat 的维度大于1且最后一个维度大于1,则说明 y_hat 是一个包含多个类别概率的tensor。\n",
        "    #这种情况下,需要使用 argmax 函数找出每个样本预测概率最高的类别索引,赋值给 y_hat。\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = argmax(y_hat, axis=1)\n",
        "  #使用astype函数将y_hat的数据类型转换为和y相同的类型,方便比较\n",
        "  #比较是否相等，如果相等就得到布尔类型的tensor\n",
        "    cmp = astype(y_hat, y.dtype) == y\n",
        "  #使用 reduce_sum 函数统计 cmp 中为True的元素个数,得到预测正确的样本数\n",
        "    return float(reduce_sum(astype(cmp, y.dtype)))\n",
        "# def accuracy(y_hat, y):\n",
        "#     \"\"\"Compute the number of correct predictions.\"\"\"\n",
        "#     if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "#         y_hat = y_hat.argmax(dim=1)\n",
        "#     cmp = y_hat.type(y.dtype) == y\n",
        "#     return float(cmp.type(y.dtype).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "U5Pzk1fA4emE"
      },
      "outputs": [],
      "source": [
        "def train_batch(net, X, y, loss, trainer, devices):\n",
        "    # 转移到一个device上\n",
        "    if isinstance(X, list):\n",
        "        # Required for BERT fine-tuning (to be covered later)\n",
        "        X = [x.to(devices[0]) for x in X]\n",
        "    else:\n",
        "        X = X.to(devices[0])\n",
        "    y = y.to(devices[0])\n",
        "    #训练\n",
        "    net.train()\n",
        "    #梯度为0\n",
        "    trainer.zero_grad()\n",
        "    #前向传播\n",
        "    pred = net(X)\n",
        "    #计算损失\n",
        "    l = loss(pred, y)\n",
        "    #反向传播更新参数\n",
        "    l.sum().backward()\n",
        "    trainer.step()\n",
        "\n",
        "    #本批次的损失和准确度\n",
        "    train_loss_sum = l.sum()\n",
        "    train_acc_sum = accuracy(pred, y)\n",
        "    return train_loss_sum, train_acc_sum\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BJlvc79FDkIw"
      },
      "outputs": [],
      "source": [
        "def k_fold(net, criterion, lr_period, lr_decay, lr, wd, trainset, devices, num_epochs=1, batch_size=128):\n",
        "    # 使用 KFold 进行 10 折交叉验证，shuffle=True 表示打乱数据集\n",
        "    kfold = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "    # for epoch in range(num_epochs):\n",
        "        # 一折交叉验证\n",
        "    for fold, (train_indices, val_indices) in enumerate(kfold.split(trainset)):\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Fold {fold+1}')\n",
        "\n",
        "        trainset_fold = torch.utils.data.Subset(trainset, train_indices)  # 获取当前折的训练集\n",
        "        valset_fold = torch.utils.data.Subset(trainset, val_indices)  # 获取当前折的验证集\n",
        "\n",
        "        #当前折训练数据集\n",
        "        trainloader_fold = torch.utils.data.DataLoader(trainset_fold, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "        #当前折验证数据集\n",
        "        valloader_fold = torch.utils.data.DataLoader(valset_fold, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "        # 为每一折创建一个新的网络实例\n",
        "        model = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
        "\n",
        "          # sgd优化器\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
        "        #学习率调度器，\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_period, lr_decay)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            \n",
        "            \n",
        "            #running_loss 用于记录整个训练过程中的累积损失值。\n",
        "            running_loss = 0.0\n",
        "            model.train()\n",
        "\n",
        "            #循环训练集的特征和标签\n",
        "            for i, (inputs, labels) in enumerate(trainloader_fold):\n",
        "              #计算每个批次的损失和返回预测正确的样本数，\n",
        "              #net 特征 标签 损失函数 sgd优化器 设备\n",
        "                loss, acc = train_batch(model, inputs, labels, criterion, optimizer, devices)\n",
        "                #用正确的样本数/当前batch的总样本数即可\n",
        "                Acc=float(acc) / labels.shape[0]\n",
        "\n",
        "              #将当前批次的损失值 loss 加到 running_loss 变量中。\n",
        "                running_loss += loss.item()\n",
        "              #检查当前批次的索引是否为训练数据批次总数的 1/5 倍,或者是否为最后一个批次。\n",
        "                if (i + 1) % (len(trainloader_fold) // 5) == 0 or i == len(trainloader_fold) - 1:\n",
        "                  #当前batch的索引和总batch数量，当前的平均损失，当前的准确率\n",
        "                    print(f'Batch [{i+1}/{len(trainloader_fold)}], Loss: {running_loss / (i + 1):.4f}, Acc: {Acc:.2f}')\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            for inputs, labels in valloader_fold:\n",
        "                inputs = inputs.to(devices[0])\n",
        "                labels = labels.to(devices[0])\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "            print(f'Validation Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "      # 绘制损失、训练集正确率和验证集正确率\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(train_losses)\n",
        "    plt.title('Training Loss')\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(train_accs)\n",
        "    plt.title('Training Accuracy')\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Accuracy')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(val_accs)\n",
        "    plt.title('Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2swg6sg4emE"
      },
      "source": [
        "## ResNet模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc_FCUk-4emF"
      },
      "source": [
        "残差块"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wuZxJ8Zq4emF"
      },
      "outputs": [],
      "source": [
        "from torch.nn import functional as F\n",
        "#画图表示\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, input_channels, num_channels,\n",
        "                 use_1x1conv=False, strides=1):\n",
        "        #初始化\n",
        "        super().__init__()\n",
        "        #两个卷积层，内核大小都为3，\n",
        "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
        "                               kernel_size=3, padding=1, stride=strides)\n",
        "        #输入通道为上一层的输出通道\n",
        "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
        "                               kernel_size=3, padding=1)\n",
        "        if use_1x1conv:#如果不使用的话，在应用Relu前，将输入添加到输出；如果使用，通过添加1×1卷积来调整通道和分辨率\n",
        "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
        "                                   kernel_size=1, stride=strides)\n",
        "        else:\n",
        "            self.conv3 = None\n",
        "        #两个批量归一化层\n",
        "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "        if self.conv3:\n",
        "            X = self.conv3(X)\n",
        "        Y += X\n",
        "        return F.relu(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-5i_NbFU4emF"
      },
      "outputs": [],
      "source": [
        "def resnet18(num_classes, in_channels=1):\n",
        "    \n",
        "    def resnet_block(in_channels, out_channels, num_residuals,\n",
        "                     first_block=False):\n",
        "        blk = []\n",
        "        for i in range(num_residuals):\n",
        "            if i == 0 and not first_block:\n",
        "                blk.append(\n",
        "                    Residual(in_channels, out_channels, use_1x1conv=True,\n",
        "                                 strides=2))\n",
        "            else:\n",
        "                blk.append(Residual(out_channels, out_channels))\n",
        "        return nn.Sequential(*blk)\n",
        "\n",
        "    # This model uses a smaller convolution kernel, stride, and padding and\n",
        "    #不可以删掉最大池化层，可能会使梯度消失，使网络的感受野减小\n",
        "    net = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(64), nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))       \n",
        "    net.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\n",
        "    net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\n",
        "    net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\n",
        "    net.add_module(\"resnet_block4\", resnet_block(256, 512, 2))\n",
        "    net.add_module(\"global_avg_pool\", nn.AdaptiveAvgPool2d((1, 1)))\n",
        "    net.add_module(\"fc\",\n",
        "                   nn.Sequential(nn.Flatten(), nn.Linear(512, num_classes)))\n",
        "    return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "giWmXSrU4emF"
      },
      "outputs": [],
      "source": [
        "def get_net():\n",
        "    num_classes = 10\n",
        "    net = resnet18(num_classes, 3)\n",
        "    return net\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(reduction=\"none\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conv2d output shape:\t torch.Size([4, 64, 32, 32])\n",
            "BatchNorm2d output shape:\t torch.Size([4, 64, 32, 32])\n",
            "ReLU output shape:\t torch.Size([4, 64, 32, 32])\n",
            "MaxPool2d output shape:\t torch.Size([4, 64, 16, 16])\n",
            "Sequential output shape:\t torch.Size([4, 64, 16, 16])\n",
            "Sequential output shape:\t torch.Size([4, 128, 8, 8])\n",
            "Sequential output shape:\t torch.Size([4, 256, 4, 4])\n",
            "Sequential output shape:\t torch.Size([4, 512, 2, 2])\n",
            "AdaptiveAvgPool2d output shape:\t torch.Size([4, 512, 1, 1])\n",
            "Sequential output shape:\t torch.Size([4, 10])\n"
          ]
        }
      ],
      "source": [
        "X = torch.rand(size=(4, 3, 32, 32))\n",
        "net=get_net()\n",
        "for layer in net:\n",
        "    X = layer(X)\n",
        "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KoJKIujw6YOS"
      },
      "outputs": [],
      "source": [
        "def try_all_gpus():\n",
        "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\"\"\"\n",
        "    devices = [\n",
        "        torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
        "    return devices if devices else [torch.device('cpu')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iR7u-fHK4emF",
        "outputId": "698dd61f-955a-4a79-88b4-576b09c3ce03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Fold 1\n",
            "Batch [70/352], Loss: 243.2207, Acc: 0.40\n",
            "Batch [140/352], Loss: 222.2294, Acc: 0.46\n",
            "Batch [210/352], Loss: 208.2371, Acc: 0.48\n",
            "Batch [280/352], Loss: 197.6485, Acc: 0.63\n",
            "Batch [350/352], Loss: 188.4211, Acc: 0.46\n",
            "Batch [352/352], Loss: 187.9893, Acc: 0.56\n",
            "Validation Accuracy: 56.76%\n",
            "Epoch [1/10], Fold 2\n",
            "Batch [70/352], Loss: 137.1895, Acc: 0.62\n",
            "Batch [140/352], Loss: 132.8174, Acc: 0.61\n",
            "Batch [210/352], Loss: 127.6359, Acc: 0.77\n",
            "Batch [280/352], Loss: 123.9510, Acc: 0.78\n",
            "Batch [350/352], Loss: 121.8429, Acc: 0.66\n",
            "Batch [352/352], Loss: 121.7027, Acc: 0.68\n",
            "Validation Accuracy: 62.96%\n",
            "Epoch [1/10], Fold 3\n",
            "Batch [70/352], Loss: 99.9998, Acc: 0.77\n",
            "Batch [140/352], Loss: 98.4520, Acc: 0.77\n",
            "Batch [210/352], Loss: 97.8068, Acc: 0.68\n",
            "Batch [280/352], Loss: 96.2366, Acc: 0.73\n",
            "Batch [350/352], Loss: 95.0691, Acc: 0.78\n",
            "Batch [352/352], Loss: 94.8785, Acc: 0.71\n",
            "Validation Accuracy: 73.16%\n",
            "Epoch [1/10], Fold 4\n",
            "Batch [70/352], Loss: 80.7703, Acc: 0.85\n",
            "Batch [140/352], Loss: 81.5825, Acc: 0.70\n",
            "Batch [210/352], Loss: 80.9852, Acc: 0.74\n",
            "Batch [280/352], Loss: 80.5663, Acc: 0.81\n",
            "Batch [350/352], Loss: 79.9126, Acc: 0.85\n",
            "Batch [352/352], Loss: 79.7666, Acc: 0.74\n",
            "Validation Accuracy: 76.98%\n",
            "Epoch [1/10], Fold 5\n",
            "Batch [70/352], Loss: 68.9268, Acc: 0.82\n",
            "Batch [140/352], Loss: 70.5707, Acc: 0.86\n",
            "Batch [210/352], Loss: 69.6258, Acc: 0.83\n",
            "Batch [280/352], Loss: 69.7164, Acc: 0.84\n",
            "Batch [350/352], Loss: 69.3587, Acc: 0.84\n",
            "Batch [352/352], Loss: 69.2751, Acc: 0.71\n",
            "Validation Accuracy: 79.86%\n",
            "Epoch [1/10], Fold 6\n",
            "Batch [70/352], Loss: 62.9071, Acc: 0.88\n",
            "Batch [140/352], Loss: 63.1167, Acc: 0.84\n",
            "Batch [210/352], Loss: 64.1371, Acc: 0.80\n",
            "Batch [280/352], Loss: 63.3348, Acc: 0.79\n",
            "Batch [350/352], Loss: 62.7079, Acc: 0.81\n",
            "Batch [352/352], Loss: 62.6886, Acc: 0.72\n",
            "Validation Accuracy: 79.70%\n",
            "Epoch [1/10], Fold 7\n",
            "Batch [70/352], Loss: 56.2072, Acc: 0.81\n",
            "Batch [140/352], Loss: 56.2447, Acc: 0.93\n",
            "Batch [210/352], Loss: 56.2602, Acc: 0.84\n",
            "Batch [280/352], Loss: 56.5056, Acc: 0.85\n",
            "Batch [350/352], Loss: 56.2972, Acc: 0.83\n",
            "Batch [352/352], Loss: 56.2074, Acc: 0.86\n",
            "Validation Accuracy: 81.88%\n",
            "Epoch [1/10], Fold 8\n",
            "Batch [70/352], Loss: 49.9099, Acc: 0.87\n",
            "Batch [140/352], Loss: 52.3438, Acc: 0.81\n",
            "Batch [210/352], Loss: 52.4891, Acc: 0.85\n",
            "Batch [280/352], Loss: 52.5375, Acc: 0.86\n",
            "Batch [350/352], Loss: 52.2114, Acc: 0.84\n",
            "Batch [352/352], Loss: 52.1496, Acc: 0.83\n",
            "Validation Accuracy: 86.76%\n",
            "Epoch [1/10], Fold 9\n",
            "Batch [70/352], Loss: 45.0045, Acc: 0.90\n",
            "Batch [140/352], Loss: 46.0121, Acc: 0.87\n",
            "Batch [210/352], Loss: 46.9282, Acc: 0.92\n",
            "Batch [280/352], Loss: 47.1177, Acc: 0.85\n",
            "Batch [350/352], Loss: 47.4577, Acc: 0.92\n",
            "Batch [352/352], Loss: 47.3988, Acc: 0.92\n",
            "Validation Accuracy: 86.70%\n",
            "Epoch [1/10], Fold 10\n",
            "Batch [70/352], Loss: 42.5902, Acc: 0.88\n",
            "Batch [140/352], Loss: 43.6221, Acc: 0.88\n",
            "Batch [210/352], Loss: 43.4140, Acc: 0.90\n",
            "Batch [280/352], Loss: 43.7851, Acc: 0.85\n",
            "Batch [350/352], Loss: 43.4803, Acc: 0.89\n",
            "Batch [352/352], Loss: 43.4716, Acc: 0.89\n",
            "Validation Accuracy: 88.22%\n",
            "Epoch [2/10], Fold 1\n",
            "Batch [70/352], Loss: 38.2320, Acc: 0.90\n",
            "Batch [140/352], Loss: 39.9993, Acc: 0.89\n",
            "Batch [210/352], Loss: 40.5011, Acc: 0.88\n",
            "Batch [280/352], Loss: 40.3357, Acc: 0.91\n",
            "Batch [350/352], Loss: 40.1110, Acc: 0.88\n",
            "Batch [352/352], Loss: 40.0812, Acc: 0.85\n",
            "Validation Accuracy: 86.90%\n",
            "Epoch [2/10], Fold 2\n",
            "Batch [70/352], Loss: 36.8336, Acc: 0.89\n",
            "Batch [140/352], Loss: 36.5715, Acc: 0.91\n",
            "Batch [210/352], Loss: 36.9508, Acc: 0.91\n",
            "Batch [280/352], Loss: 36.8090, Acc: 0.85\n",
            "Batch [350/352], Loss: 37.0436, Acc: 0.91\n",
            "Batch [352/352], Loss: 36.9553, Acc: 0.96\n",
            "Validation Accuracy: 88.54%\n",
            "Epoch [2/10], Fold 3\n",
            "Batch [70/352], Loss: 35.4370, Acc: 0.89\n",
            "Batch [140/352], Loss: 35.5760, Acc: 0.84\n",
            "Batch [210/352], Loss: 35.6702, Acc: 0.88\n",
            "Batch [280/352], Loss: 35.4503, Acc: 0.92\n",
            "Batch [350/352], Loss: 35.5594, Acc: 0.92\n",
            "Batch [352/352], Loss: 35.5101, Acc: 0.94\n",
            "Validation Accuracy: 90.32%\n",
            "Epoch [2/10], Fold 4\n",
            "Batch [70/352], Loss: 29.3788, Acc: 0.91\n",
            "Batch [140/352], Loss: 31.0082, Acc: 0.91\n",
            "Batch [210/352], Loss: 31.3444, Acc: 0.91\n",
            "Batch [280/352], Loss: 31.8567, Acc: 0.88\n",
            "Batch [350/352], Loss: 32.2492, Acc: 0.93\n",
            "Batch [352/352], Loss: 32.1950, Acc: 0.94\n",
            "Validation Accuracy: 90.96%\n",
            "Epoch [2/10], Fold 5\n",
            "Batch [70/352], Loss: 28.3718, Acc: 0.94\n",
            "Batch [140/352], Loss: 28.9837, Acc: 0.90\n",
            "Batch [210/352], Loss: 29.3506, Acc: 0.94\n",
            "Batch [280/352], Loss: 29.3794, Acc: 0.93\n",
            "Batch [350/352], Loss: 30.1590, Acc: 0.88\n",
            "Batch [352/352], Loss: 30.1236, Acc: 0.96\n",
            "Validation Accuracy: 90.12%\n",
            "Epoch [2/10], Fold 6\n",
            "Batch [70/352], Loss: 25.0452, Acc: 0.90\n",
            "Batch [140/352], Loss: 26.3736, Acc: 0.91\n",
            "Batch [210/352], Loss: 27.0832, Acc: 0.91\n",
            "Batch [280/352], Loss: 27.8943, Acc: 0.93\n",
            "Batch [350/352], Loss: 28.3633, Acc: 0.91\n",
            "Batch [352/352], Loss: 28.2696, Acc: 0.96\n",
            "Validation Accuracy: 92.34%\n",
            "Epoch [2/10], Fold 7\n",
            "Batch [70/352], Loss: 24.0563, Acc: 0.93\n",
            "Batch [140/352], Loss: 25.0575, Acc: 0.93\n",
            "Batch [210/352], Loss: 26.1239, Acc: 0.91\n",
            "Batch [280/352], Loss: 26.2171, Acc: 0.94\n",
            "Batch [350/352], Loss: 26.6230, Acc: 0.95\n",
            "Batch [352/352], Loss: 26.5873, Acc: 0.86\n",
            "Validation Accuracy: 93.14%\n",
            "Epoch [2/10], Fold 8\n",
            "Batch [70/352], Loss: 24.4241, Acc: 0.92\n",
            "Batch [140/352], Loss: 23.5966, Acc: 0.95\n",
            "Batch [210/352], Loss: 24.0961, Acc: 0.91\n",
            "Batch [280/352], Loss: 24.3860, Acc: 0.95\n",
            "Batch [350/352], Loss: 24.7883, Acc: 0.94\n",
            "Batch [352/352], Loss: 24.7958, Acc: 0.92\n",
            "Validation Accuracy: 91.32%\n",
            "Epoch [2/10], Fold 9\n",
            "Batch [70/352], Loss: 22.0867, Acc: 0.95\n",
            "Batch [140/352], Loss: 22.9180, Acc: 0.90\n",
            "Batch [210/352], Loss: 23.7085, Acc: 0.93\n",
            "Batch [280/352], Loss: 24.0225, Acc: 0.96\n",
            "Batch [350/352], Loss: 24.1588, Acc: 0.91\n",
            "Batch [352/352], Loss: 24.1428, Acc: 0.90\n",
            "Validation Accuracy: 92.32%\n",
            "Epoch [2/10], Fold 10\n",
            "Batch [70/352], Loss: 20.9604, Acc: 0.95\n",
            "Batch [140/352], Loss: 21.0253, Acc: 0.95\n",
            "Batch [210/352], Loss: 20.8909, Acc: 0.95\n",
            "Batch [280/352], Loss: 21.3639, Acc: 0.94\n",
            "Batch [350/352], Loss: 21.8833, Acc: 0.96\n",
            "Batch [352/352], Loss: 21.8807, Acc: 0.96\n",
            "Validation Accuracy: 93.46%\n",
            "Epoch [3/10], Fold 1\n",
            "Batch [70/352], Loss: 19.4243, Acc: 0.95\n",
            "Batch [140/352], Loss: 19.8523, Acc: 0.94\n",
            "Batch [210/352], Loss: 20.4010, Acc: 0.95\n",
            "Batch [280/352], Loss: 20.9555, Acc: 0.89\n",
            "Batch [350/352], Loss: 21.3207, Acc: 0.95\n",
            "Batch [352/352], Loss: 21.2494, Acc: 0.96\n",
            "Validation Accuracy: 93.58%\n",
            "Epoch [3/10], Fold 2\n",
            "Batch [70/352], Loss: 18.3651, Acc: 0.95\n",
            "Batch [140/352], Loss: 19.3975, Acc: 0.93\n",
            "Batch [210/352], Loss: 19.6822, Acc: 0.93\n",
            "Batch [280/352], Loss: 19.2410, Acc: 0.99\n",
            "Batch [350/352], Loss: 19.7197, Acc: 0.98\n",
            "Batch [352/352], Loss: 19.6629, Acc: 0.96\n",
            "Validation Accuracy: 94.34%\n",
            "Epoch [3/10], Fold 3\n",
            "Batch [70/352], Loss: 17.4355, Acc: 0.98\n",
            "Batch [140/352], Loss: 18.2848, Acc: 0.95\n",
            "Batch [210/352], Loss: 18.6303, Acc: 0.98\n",
            "Batch [280/352], Loss: 18.5508, Acc: 0.99\n",
            "Batch [350/352], Loss: 19.0226, Acc: 0.98\n",
            "Batch [352/352], Loss: 18.9847, Acc: 0.94\n",
            "Validation Accuracy: 93.78%\n",
            "Epoch [3/10], Fold 4\n",
            "Batch [70/352], Loss: 17.4052, Acc: 0.95\n",
            "Batch [140/352], Loss: 17.3497, Acc: 0.96\n",
            "Batch [210/352], Loss: 17.7255, Acc: 0.95\n",
            "Batch [280/352], Loss: 17.8590, Acc: 0.97\n",
            "Batch [350/352], Loss: 17.8992, Acc: 0.97\n",
            "Batch [352/352], Loss: 17.8431, Acc: 0.99\n",
            "Validation Accuracy: 95.26%\n",
            "Epoch [3/10], Fold 5\n",
            "Batch [70/352], Loss: 14.5935, Acc: 0.98\n",
            "Batch [140/352], Loss: 15.2668, Acc: 0.92\n",
            "Batch [210/352], Loss: 15.6101, Acc: 0.98\n",
            "Batch [280/352], Loss: 16.3531, Acc: 0.98\n",
            "Batch [350/352], Loss: 16.5299, Acc: 0.97\n",
            "Batch [352/352], Loss: 16.5259, Acc: 0.93\n",
            "Validation Accuracy: 94.94%\n",
            "Epoch [3/10], Fold 6\n",
            "Batch [70/352], Loss: 15.0871, Acc: 0.96\n",
            "Batch [140/352], Loss: 15.8835, Acc: 0.96\n",
            "Batch [210/352], Loss: 15.8002, Acc: 0.97\n",
            "Batch [280/352], Loss: 15.8802, Acc: 0.96\n",
            "Batch [350/352], Loss: 16.0611, Acc: 0.94\n",
            "Batch [352/352], Loss: 16.0482, Acc: 0.92\n",
            "Validation Accuracy: 95.48%\n",
            "Epoch [3/10], Fold 7\n",
            "Batch [70/352], Loss: 13.9087, Acc: 0.95\n",
            "Batch [140/352], Loss: 14.6047, Acc: 0.95\n",
            "Batch [210/352], Loss: 14.6636, Acc: 0.98\n",
            "Batch [280/352], Loss: 15.2509, Acc: 0.95\n",
            "Batch [350/352], Loss: 15.6653, Acc: 0.97\n",
            "Batch [352/352], Loss: 15.6626, Acc: 0.90\n",
            "Validation Accuracy: 95.08%\n",
            "Epoch [3/10], Fold 8\n",
            "Batch [70/352], Loss: 14.1468, Acc: 0.98\n",
            "Batch [140/352], Loss: 14.3506, Acc: 0.96\n",
            "Batch [210/352], Loss: 14.8807, Acc: 0.96\n",
            "Batch [280/352], Loss: 14.9082, Acc: 0.91\n",
            "Batch [350/352], Loss: 15.0046, Acc: 0.97\n",
            "Batch [352/352], Loss: 14.9825, Acc: 0.99\n",
            "Validation Accuracy: 96.42%\n",
            "Epoch [3/10], Fold 9\n",
            "Batch [70/352], Loss: 13.1501, Acc: 0.95\n",
            "Batch [140/352], Loss: 13.4077, Acc: 0.93\n",
            "Batch [210/352], Loss: 14.2312, Acc: 0.95\n",
            "Batch [280/352], Loss: 14.2076, Acc: 0.97\n",
            "Batch [350/352], Loss: 14.0325, Acc: 0.98\n",
            "Batch [352/352], Loss: 14.0200, Acc: 0.99\n",
            "Validation Accuracy: 96.60%\n",
            "Epoch [3/10], Fold 10\n",
            "Batch [70/352], Loss: 11.9649, Acc: 0.96\n",
            "Batch [140/352], Loss: 11.8116, Acc: 0.97\n",
            "Batch [210/352], Loss: 13.0292, Acc: 0.95\n",
            "Batch [280/352], Loss: 13.2140, Acc: 0.98\n",
            "Batch [350/352], Loss: 13.0922, Acc: 0.97\n",
            "Batch [352/352], Loss: 13.0798, Acc: 0.96\n",
            "Validation Accuracy: 96.74%\n",
            "Epoch [4/10], Fold 1\n",
            "Batch [70/352], Loss: 10.7187, Acc: 0.97\n",
            "Batch [140/352], Loss: 11.4679, Acc: 0.96\n",
            "Batch [210/352], Loss: 11.8094, Acc: 0.99\n",
            "Batch [280/352], Loss: 12.3165, Acc: 0.98\n",
            "Batch [350/352], Loss: 12.4791, Acc: 0.95\n",
            "Batch [352/352], Loss: 12.4694, Acc: 0.94\n",
            "Validation Accuracy: 95.90%\n",
            "Epoch [4/10], Fold 2\n",
            "Batch [70/352], Loss: 10.5824, Acc: 0.98\n",
            "Batch [140/352], Loss: 10.3258, Acc: 0.95\n",
            "Batch [210/352], Loss: 10.7079, Acc: 0.98\n",
            "Batch [280/352], Loss: 11.3593, Acc: 0.95\n",
            "Batch [350/352], Loss: 11.6987, Acc: 0.97\n",
            "Batch [352/352], Loss: 11.6630, Acc: 0.99\n",
            "Validation Accuracy: 96.48%\n",
            "Epoch [4/10], Fold 3\n",
            "Batch [70/352], Loss: 10.0532, Acc: 0.97\n",
            "Batch [140/352], Loss: 10.7395, Acc: 0.96\n",
            "Batch [210/352], Loss: 11.1934, Acc: 0.96\n",
            "Batch [280/352], Loss: 11.4033, Acc: 0.97\n",
            "Batch [350/352], Loss: 11.4897, Acc: 0.98\n",
            "Batch [352/352], Loss: 11.4703, Acc: 0.99\n",
            "Validation Accuracy: 96.10%\n",
            "Epoch [4/10], Fold 4\n",
            "Batch [70/352], Loss: 10.1185, Acc: 0.98\n",
            "Batch [140/352], Loss: 10.7488, Acc: 0.97\n",
            "Batch [210/352], Loss: 10.9202, Acc: 0.96\n",
            "Batch [280/352], Loss: 11.3666, Acc: 0.97\n",
            "Batch [350/352], Loss: 11.2252, Acc: 0.96\n",
            "Batch [352/352], Loss: 11.1886, Acc: 0.99\n",
            "Validation Accuracy: 96.96%\n",
            "Epoch [4/10], Fold 5\n",
            "Batch [70/352], Loss: 8.8711, Acc: 0.98\n",
            "Batch [140/352], Loss: 10.3061, Acc: 0.95\n",
            "Batch [210/352], Loss: 10.4525, Acc: 0.97\n",
            "Batch [280/352], Loss: 10.7276, Acc: 0.96\n",
            "Batch [350/352], Loss: 11.0384, Acc: 0.98\n",
            "Batch [352/352], Loss: 11.0119, Acc: 0.97\n",
            "Validation Accuracy: 97.12%\n",
            "Epoch [4/10], Fold 6\n",
            "Batch [70/352], Loss: 9.3881, Acc: 0.99\n",
            "Batch [140/352], Loss: 9.4744, Acc: 0.98\n",
            "Batch [210/352], Loss: 9.8673, Acc: 0.96\n",
            "Batch [280/352], Loss: 10.1607, Acc: 0.98\n",
            "Batch [350/352], Loss: 10.4876, Acc: 0.98\n",
            "Batch [352/352], Loss: 10.4698, Acc: 0.97\n",
            "Validation Accuracy: 97.02%\n",
            "Epoch [4/10], Fold 7\n",
            "Batch [70/352], Loss: 10.1184, Acc: 0.98\n",
            "Batch [140/352], Loss: 10.3482, Acc: 0.98\n",
            "Batch [210/352], Loss: 9.9604, Acc: 0.96\n",
            "Batch [280/352], Loss: 9.9449, Acc: 0.96\n",
            "Batch [350/352], Loss: 10.1232, Acc: 0.95\n",
            "Batch [352/352], Loss: 10.0957, Acc: 1.00\n",
            "Validation Accuracy: 97.50%\n",
            "Epoch [4/10], Fold 8\n",
            "Batch [70/352], Loss: 9.1663, Acc: 0.95\n",
            "Batch [140/352], Loss: 9.2562, Acc: 0.98\n",
            "Batch [210/352], Loss: 9.3803, Acc: 0.96\n",
            "Batch [280/352], Loss: 9.4331, Acc: 0.95\n",
            "Batch [350/352], Loss: 9.3473, Acc: 0.99\n",
            "Batch [352/352], Loss: 9.3657, Acc: 0.94\n",
            "Validation Accuracy: 97.42%\n",
            "Epoch [4/10], Fold 9\n",
            "Batch [70/352], Loss: 7.9701, Acc: 0.99\n",
            "Batch [140/352], Loss: 9.0085, Acc: 0.98\n",
            "Batch [210/352], Loss: 8.7564, Acc: 0.97\n",
            "Batch [280/352], Loss: 8.9437, Acc: 0.98\n",
            "Batch [350/352], Loss: 9.0091, Acc: 0.98\n",
            "Batch [352/352], Loss: 9.0013, Acc: 0.96\n",
            "Validation Accuracy: 97.16%\n",
            "Epoch [4/10], Fold 10\n",
            "Batch [70/352], Loss: 8.1795, Acc: 0.98\n",
            "Batch [140/352], Loss: 8.2156, Acc: 0.99\n",
            "Batch [210/352], Loss: 8.3119, Acc: 0.96\n",
            "Batch [280/352], Loss: 8.2946, Acc: 0.98\n",
            "Batch [350/352], Loss: 8.3931, Acc: 0.99\n",
            "Batch [352/352], Loss: 8.3897, Acc: 0.96\n",
            "Validation Accuracy: 98.28%\n",
            "Epoch [5/10], Fold 1\n",
            "Batch [70/352], Loss: 7.5534, Acc: 0.98\n",
            "Batch [140/352], Loss: 8.1380, Acc: 0.98\n",
            "Batch [210/352], Loss: 8.8322, Acc: 0.97\n",
            "Batch [280/352], Loss: 8.8250, Acc: 0.98\n",
            "Batch [350/352], Loss: 8.8113, Acc: 0.97\n",
            "Batch [352/352], Loss: 8.7904, Acc: 0.97\n",
            "Validation Accuracy: 98.02%\n",
            "Epoch [5/10], Fold 2\n",
            "Batch [70/352], Loss: 8.0673, Acc: 0.98\n",
            "Batch [140/352], Loss: 8.5630, Acc: 0.96\n",
            "Batch [210/352], Loss: 8.5940, Acc: 1.00\n",
            "Batch [280/352], Loss: 8.5093, Acc: 0.96\n",
            "Batch [350/352], Loss: 8.6161, Acc: 0.98\n",
            "Batch [352/352], Loss: 8.6041, Acc: 0.97\n",
            "Validation Accuracy: 97.44%\n",
            "Epoch [5/10], Fold 3\n",
            "Batch [70/352], Loss: 7.2471, Acc: 0.98\n",
            "Batch [140/352], Loss: 7.9394, Acc: 0.97\n",
            "Batch [210/352], Loss: 8.0910, Acc: 0.97\n",
            "Batch [280/352], Loss: 8.1848, Acc: 0.98\n",
            "Batch [350/352], Loss: 8.2969, Acc: 0.98\n",
            "Batch [352/352], Loss: 8.2924, Acc: 0.96\n",
            "Validation Accuracy: 97.78%\n",
            "Epoch [5/10], Fold 4\n",
            "Batch [70/352], Loss: 6.9479, Acc: 1.00\n",
            "Batch [140/352], Loss: 7.4489, Acc: 0.99\n",
            "Batch [210/352], Loss: 7.4192, Acc: 0.97\n",
            "Batch [280/352], Loss: 7.4134, Acc: 0.98\n",
            "Batch [350/352], Loss: 7.5854, Acc: 0.95\n",
            "Batch [352/352], Loss: 7.5982, Acc: 0.94\n",
            "Validation Accuracy: 98.04%\n",
            "Epoch [5/10], Fold 5\n",
            "Batch [70/352], Loss: 7.6409, Acc: 0.97\n",
            "Batch [140/352], Loss: 7.4821, Acc: 0.98\n",
            "Batch [210/352], Loss: 7.8063, Acc: 1.00\n",
            "Batch [280/352], Loss: 7.8551, Acc: 0.99\n",
            "Batch [350/352], Loss: 7.7146, Acc: 0.98\n",
            "Batch [352/352], Loss: 7.7007, Acc: 0.99\n",
            "Validation Accuracy: 97.84%\n",
            "Epoch [5/10], Fold 6\n",
            "Batch [70/352], Loss: 5.9776, Acc: 0.99\n",
            "Batch [140/352], Loss: 6.0744, Acc: 0.97\n",
            "Batch [210/352], Loss: 6.3478, Acc: 0.97\n",
            "Batch [280/352], Loss: 6.5675, Acc: 0.98\n",
            "Batch [350/352], Loss: 6.6434, Acc: 0.99\n",
            "Batch [352/352], Loss: 6.6247, Acc: 0.97\n",
            "Validation Accuracy: 98.14%\n",
            "Epoch [5/10], Fold 7\n",
            "Batch [70/352], Loss: 5.6631, Acc: 0.98\n",
            "Batch [140/352], Loss: 6.0744, Acc: 0.98\n",
            "Batch [210/352], Loss: 6.3860, Acc: 0.99\n",
            "Batch [280/352], Loss: 6.6210, Acc: 0.97\n",
            "Batch [350/352], Loss: 6.7452, Acc: 0.95\n",
            "Batch [352/352], Loss: 6.7434, Acc: 0.99\n",
            "Validation Accuracy: 98.42%\n",
            "Epoch [5/10], Fold 8\n",
            "Batch [70/352], Loss: 6.1646, Acc: 0.96\n",
            "Batch [140/352], Loss: 6.7921, Acc: 0.96\n",
            "Batch [210/352], Loss: 6.6525, Acc: 1.00\n",
            "Batch [280/352], Loss: 6.4015, Acc: 0.98\n",
            "Batch [350/352], Loss: 6.4906, Acc: 0.98\n",
            "Batch [352/352], Loss: 6.4867, Acc: 0.94\n",
            "Validation Accuracy: 98.26%\n",
            "Epoch [5/10], Fold 9\n",
            "Batch [70/352], Loss: 6.1279, Acc: 0.98\n",
            "Batch [140/352], Loss: 6.5015, Acc: 0.98\n",
            "Batch [210/352], Loss: 6.6894, Acc: 0.99\n",
            "Batch [280/352], Loss: 6.8306, Acc: 0.96\n",
            "Batch [350/352], Loss: 6.8402, Acc: 0.95\n",
            "Batch [352/352], Loss: 6.8232, Acc: 0.97\n",
            "Validation Accuracy: 98.30%\n",
            "Epoch [5/10], Fold 10\n",
            "Batch [70/352], Loss: 5.3740, Acc: 1.00\n",
            "Batch [140/352], Loss: 6.0080, Acc: 0.98\n",
            "Batch [210/352], Loss: 5.9435, Acc: 0.98\n",
            "Batch [280/352], Loss: 5.9674, Acc: 0.97\n",
            "Batch [350/352], Loss: 6.0062, Acc: 0.97\n",
            "Batch [352/352], Loss: 6.0143, Acc: 0.97\n",
            "Validation Accuracy: 98.28%\n",
            "Epoch [6/10], Fold 1\n",
            "Batch [70/352], Loss: 5.1758, Acc: 0.97\n",
            "Batch [140/352], Loss: 5.6164, Acc: 0.98\n",
            "Batch [210/352], Loss: 5.7321, Acc: 0.99\n",
            "Batch [280/352], Loss: 5.5846, Acc: 0.98\n",
            "Batch [350/352], Loss: 6.0077, Acc: 0.96\n",
            "Batch [352/352], Loss: 6.0031, Acc: 0.97\n",
            "Validation Accuracy: 98.16%\n",
            "Epoch [6/10], Fold 2\n",
            "Batch [70/352], Loss: 5.5468, Acc: 0.99\n",
            "Batch [140/352], Loss: 5.4623, Acc: 1.00\n",
            "Batch [210/352], Loss: 5.6488, Acc: 0.99\n",
            "Batch [280/352], Loss: 5.9214, Acc: 0.98\n",
            "Batch [350/352], Loss: 6.0501, Acc: 0.98\n",
            "Batch [352/352], Loss: 6.0267, Acc: 1.00\n",
            "Validation Accuracy: 98.16%\n",
            "Epoch [6/10], Fold 3\n",
            "Batch [70/352], Loss: 5.5777, Acc: 0.98\n",
            "Batch [140/352], Loss: 5.5280, Acc: 0.99\n",
            "Batch [210/352], Loss: 5.5120, Acc: 0.98\n",
            "Batch [280/352], Loss: 5.6274, Acc: 0.99\n",
            "Batch [350/352], Loss: 5.6162, Acc: 0.99\n",
            "Batch [352/352], Loss: 5.6147, Acc: 0.97\n",
            "Validation Accuracy: 98.54%\n",
            "Epoch [6/10], Fold 4\n",
            "Batch [70/352], Loss: 5.3123, Acc: 0.99\n",
            "Batch [140/352], Loss: 5.2783, Acc: 0.99\n",
            "Batch [210/352], Loss: 5.3782, Acc: 0.98\n",
            "Batch [280/352], Loss: 5.3777, Acc: 0.98\n",
            "Batch [350/352], Loss: 5.4073, Acc: 0.98\n",
            "Batch [352/352], Loss: 5.4043, Acc: 0.99\n",
            "Validation Accuracy: 98.60%\n",
            "Epoch [6/10], Fold 5\n",
            "Batch [70/352], Loss: 4.7916, Acc: 0.99\n",
            "Batch [140/352], Loss: 5.1998, Acc: 0.98\n",
            "Batch [210/352], Loss: 5.3123, Acc: 1.00\n",
            "Batch [280/352], Loss: 5.3569, Acc: 0.98\n",
            "Batch [350/352], Loss: 5.3275, Acc: 0.98\n",
            "Batch [352/352], Loss: 5.3335, Acc: 0.99\n",
            "Validation Accuracy: 98.46%\n",
            "Epoch [6/10], Fold 6\n",
            "Batch [70/352], Loss: 4.7580, Acc: 0.99\n",
            "Batch [140/352], Loss: 4.6967, Acc: 0.98\n",
            "Batch [210/352], Loss: 4.9200, Acc: 1.00\n",
            "Batch [280/352], Loss: 4.9015, Acc: 0.99\n",
            "Batch [350/352], Loss: 5.1330, Acc: 0.96\n",
            "Batch [352/352], Loss: 5.1369, Acc: 1.00\n",
            "Validation Accuracy: 98.64%\n",
            "Epoch [6/10], Fold 7\n",
            "Batch [70/352], Loss: 5.4502, Acc: 1.00\n",
            "Batch [140/352], Loss: 5.3956, Acc: 1.00\n",
            "Batch [210/352], Loss: 5.5057, Acc: 0.98\n",
            "Batch [280/352], Loss: 5.3732, Acc: 0.99\n",
            "Batch [350/352], Loss: 5.5157, Acc: 0.99\n",
            "Batch [352/352], Loss: 5.5114, Acc: 0.99\n",
            "Validation Accuracy: 98.80%\n",
            "Epoch [6/10], Fold 8\n",
            "Batch [70/352], Loss: 4.2322, Acc: 0.98\n",
            "Batch [140/352], Loss: 4.5358, Acc: 0.99\n",
            "Batch [210/352], Loss: 4.5441, Acc: 0.99\n",
            "Batch [280/352], Loss: 4.4525, Acc: 0.98\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-e95eff697356>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlr_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,lr_decay)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mk_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-60a906e5c7fc>\u001b[0m in \u001b[0;36mk_fold\u001b[0;34m(net, criterion, lr_period, lr_decay, lr, wd, trainset, devices, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m     33\u001b[0m               \u001b[0;31m#计算每个批次的损失和返回预测正确的样本数，\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m               \u001b[0;31m#net 特征 标签 损失函数 sgd优化器 设备\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0;31m#用正确的样本数/当前batch的总样本数即可\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mAcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-d76e9986d3f7>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(net, X, y, loss, trainer, devices)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#本批次的损失和准确度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtrain_loss_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtrain_acc_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loss_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-078578ccfa4c>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(y_hat, y)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m#使用 reduce_sum 函数统计 cmp 中为True的元素个数,得到预测正确的样本数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# def accuracy(y_hat, y):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#     \"\"\"Compute the number of correct predictions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 使用示例\n",
        "device,num_epochs, lr, wd =try_all_gpus(),20, 2e-4, 5e-4\n",
        "lr_period, lr_decay, net = 4, 0.9, get_net()\n",
        "# train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,lr_decay)\n",
        "k_fold(net, criterion, lr_period, lr_decay, lr, wd, trainset,device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "d2l",
      "language": "python",
      "name": "d2l"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
