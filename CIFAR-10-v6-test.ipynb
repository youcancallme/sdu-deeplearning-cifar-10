{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youcancallme/sdu-deeplearning-cifar-10/blob/main/CIFAR-10-v6-test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDkwnu6X4el-"
      },
      "source": [
        "# 初始化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDKs8U2z4el_"
      },
      "source": [
        "## 本地实现"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuPONzSXfdg1"
      },
      "source": [
        "首先进行的是文件读取"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j01-fgRTfjeR",
        "outputId": "81e241ba-0b7f-46be-a1e0-a199466e1afa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkP6KD4j4emC"
      },
      "source": [
        "## torchvision实现"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KumQxCz64emC"
      },
      "source": [
        "上面是我自己对数据的处理，其实torchvision提供了对cifar-10数据集的处理，并且提供了及其方便的预处理代码"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "cmu5X4aM4emD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6MeWu1R4emD"
      },
      "source": [
        "### 数据增强"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIj2nYmM4emD"
      },
      "source": [
        "图像增广，训练集进行增广，测试时标准化执行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Sw16QZnV4emD"
      },
      "outputs": [],
      "source": [
        "#已经解压的数据集路径\n",
        "#本地\n",
        "# unzip_folder_path='../cifar-10-python'\n",
        "#colab\n",
        "unzip_folder_path= '/content/drive/MyDrive/cifar-10-python'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1c7rN2oL4emD"
      },
      "outputs": [],
      "source": [
        "#训练集\n",
        "transform_train = torchvision.transforms.Compose([\n",
        "    # 在高度和宽度上将图像放大到40像素的正方形\n",
        "    torchvision.transforms.Resize(40),\n",
        "    # 生成一个面积为原始图像面积0.64～1倍的小正方形，\n",
        "    # 然后将其缩放为高度和宽度均为32像素的正方形\n",
        "    torchvision.transforms.RandomResizedCrop(32, scale=(0.64, 1.0),ratio=(1.0, 1.0)),\n",
        "    #以 50% 的概率对输入图像进行水平翻转,用于数据增强。\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    # NumPy 数组转换为 PyTorch Tensor 。\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    # 标准化图像的每个通道 三通道分别归一化，到均值为 0、标准差为 1 的分布。\n",
        "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
        "                                     [0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "#测试集\n",
        "transform_test = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
        "                                     [0.2023, 0.1994, 0.2010])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "xymu_dC04emD"
      },
      "outputs": [],
      "source": [
        "#如果不使用数据增广的话，只将数据变为tensor和标准化\n",
        "transform= torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
        "                                     [0.2023, 0.1994, 0.2010])])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "cJxK43n64emD"
      },
      "outputs": [],
      "source": [
        "#训练集 train=True加载训练集\n",
        "trainset = torchvision.datasets.CIFAR10(root=unzip_folder_path, train=True,\n",
        "                                        download=False, transform=transform_train)\n",
        "\n",
        "#测试集\n",
        "testset = torchvision.datasets.CIFAR10(root=unzip_folder_path, train=False,\n",
        "                                       download=False, transform=transform_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DIW8SNS_C7H",
        "outputId": "b3513aea-35a1-4f7c-d674-6d474c942b6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "image, label = trainset[0]\n",
        "image_size = image.size()\n",
        "image_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6oZQvPX4emD"
      },
      "source": [
        "### 创建数据加载器"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elzBKu_w4emD"
      },
      "source": [
        "DataLoader将数据集转换为可迭代的数据加载器对象。\n",
        "batch_size参数指定每个批次中的样本数量。\n",
        "shuffle=True表示在每个时期(epoch)开始时对数据进行洗牌。\n",
        "num_workers参数指定用于数据加载的线程数\n",
        "但是这里没用到啊，只有在kfold哪里用到了，而且test的还没有进行验证"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ff_mSOxK4emE"
      },
      "outputs": [],
      "source": [
        "# #训练集  batch_size=128  shuffle=True打乱数据  num_workers=2使用两个进程加载数据\n",
        "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "#                                           shuffle=True, num_workers=2)\n",
        "\n",
        "# #测试集 batch_size=128  shuffle=False不打乱数据  num_workers=2使用两个进程加载数据\n",
        "# testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "#                                          shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7aMuYZH4emE"
      },
      "source": [
        "## 1折交叉验证"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCXrvNlI4emE"
      },
      "source": [
        "使用KFold类从sklearn.model_selection库中创建了一个1折交叉验证对象。n_splits参数设置为10，表示将数据集划分为10个折（10份），shuffle=True表示在划分前对数据进行洗牌。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Et9cwLFF4emE"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=10, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "AcZ0r2nq4emE"
      },
      "outputs": [],
      "source": [
        "# argmax 函数别名定义了一个匿名函数，它接受参数 x，并调用 x.argmax(*args, **kwargs) 方法。\n",
        "# astype 函数别名定义了一个匿名函数，它接受参数 x，并调用 x.type(*args, **kwargs) 方法。\n",
        "# reduce_sum 函数别名定义了一个匿名函数，它接受参数 x，并调用 x.sum(*args, **kwargs) 方法。\n",
        "\n",
        "argmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs)\n",
        "astype = lambda x, *args, **kwargs: x.type(*args, **kwargs)\n",
        "reduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)\n",
        "def accuracy(y_hat, y):\n",
        "    #首先处理y_hat形状，如果 y_hat 的维度大于1且最后一个维度大于1,则说明 y_hat 是一个包含多个类别概率的tensor。\n",
        "    #这种情况下,需要使用 argmax 函数找出每个样本预测概率最高的类别索引,赋值给 y_hat。\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = argmax(y_hat, axis=1)\n",
        "  #使用astype函数将y_hat的数据类型转换为和y相同的类型,方便比较\n",
        "  #比较是否相等，如果相等就得到布尔类型的tensor\n",
        "    cmp = astype(y_hat, y.dtype) == y\n",
        "  #使用 reduce_sum 函数统计 cmp 中为True的元素个数,得到预测正确的样本数\n",
        "    return float(reduce_sum(astype(cmp, y.dtype)))\n",
        "# def accuracy(y_hat, y):\n",
        "#     \"\"\"Compute the number of correct predictions.\"\"\"\n",
        "#     if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "#         y_hat = y_hat.argmax(dim=1)\n",
        "#     cmp = y_hat.type(y.dtype) == y\n",
        "#     return float(cmp.type(y.dtype).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "U5Pzk1fA4emE"
      },
      "outputs": [],
      "source": [
        "def train_batch(net, X, y, loss, trainer, devices):\n",
        "    # 转移到一个device上\n",
        "    if isinstance(X, list):\n",
        "        # Required for BERT fine-tuning (to be covered later)\n",
        "        X = [x.to(devices[0]) for x in X]\n",
        "    else:\n",
        "        X = X.to(devices[0])\n",
        "    y = y.to(devices[0])\n",
        "    #训练\n",
        "    net.train()\n",
        "    #梯度为0\n",
        "    trainer.zero_grad()\n",
        "    #前向传播\n",
        "    pred = net(X)\n",
        "    #计算损失\n",
        "    l = loss(pred, y)\n",
        "    #反向传播更新参数\n",
        "    l.sum().backward()\n",
        "    trainer.step()\n",
        "\n",
        "    #本批次的损失和准确度\n",
        "    train_loss_sum = l.sum()\n",
        "    train_acc_sum = accuracy(pred, y)\n",
        "    return train_loss_sum, train_acc_sum\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#用于训练：\n",
        "def train(train_iter,valid_iter,net, criterion, lr_period, lr_decay, lr, wd, devices, num_epochs=1, batch_size=128):\n",
        "  # 为每一折创建一个新的网络实例\n",
        "    model = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
        "\n",
        "      # sgd优化器\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
        "    #学习率调度器，\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_period, lr_decay)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "\n",
        "        #running_loss 用于记录整个训练过程中的累积损失值。\n",
        "        running_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        #循环训练集的特征和标签\n",
        "        for i, (inputs, labels) in enumerate(train_iter):\n",
        "          #计算每个批次的损失和返回预测正确的样本数，\n",
        "          #net 特征 标签 损失函数 sgd优化器 设备\n",
        "            loss, acc = train_batch(model, inputs, labels, criterion, optimizer, devices)\n",
        "            #用正确的样本数/当前batch的总样本数即可\n",
        "            Acc=float(acc) / labels.shape[0]\n",
        "\n",
        "          #将当前批次的损失值 loss 加到 running_loss 变量中。\n",
        "            running_loss += loss.item()\n",
        "          #检查当前批次的索引是否为训练数据批次总数的 1/5 倍,或者是否为最后一个批次。\n",
        "            if (i + 1) % (len(train_iter) // 5) == 0 or i == len(train_iter) - 1:\n",
        "              #当前batch的索引和总batch数量，当前的平均损失，当前的准确率\n",
        "                print(f'Epoch [{epoch+1}/{num_epochs}]，Batch [{i+1}/{len(train_iter)}], Loss: {running_loss / (i + 1):.4f}, Acc: {Acc:.2f}')\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "    # with torch.no_grad():\n",
        "    if valid_iter is not None:\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in valid_iter:\n",
        "            inputs = inputs.to(devices[0])\n",
        "            labels = labels.to(devices[0])\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Validation Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CG1-AGv1H1gS"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#可以用于验证集测试\n",
        "def k_fold(net, criterion, lr_period, lr_decay, lr, wd, trainset,devices, num_epochs=1, batch_size=128):\n",
        "    # 使用 KFold 进行 10 折交叉验证，shuffle=True 表示打乱数据集\n",
        "    kfold = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "    # for epoch in range(num_epochs):\n",
        "        # 一折交叉验证\n",
        "    for fold, (train_indices, val_indices) in enumerate(kfold.split(trainset)):\n",
        "        print(f'Fold {fold+1}')\n",
        "        trainset_fold = torch.utils.data.Subset(trainset, train_indices)  # 获取当前折的训练集\n",
        "        valset_fold = torch.utils.data.Subset(trainset, val_indices)  # 获取当前折的验证集\n",
        "\n",
        "        #当前折训练数据集\n",
        "        trainloader_fold = torch.utils.data.DataLoader(trainset_fold, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "        #当前折验证数据集\n",
        "        valloader_fold = torch.utils.data.DataLoader(valset_fold, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "        train (trainloader_fold, valloader_fold,net, criterion, lr_period, lr_decay, lr, wd, devices)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "LQdtxymQHmOd"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2swg6sg4emE"
      },
      "source": [
        "## ResNet模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc_FCUk-4emF"
      },
      "source": [
        "残差块"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "wuZxJ8Zq4emF"
      },
      "outputs": [],
      "source": [
        "from torch.nn import functional as F\n",
        "#画图表示\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, input_channels, num_channels,\n",
        "                 use_1x1conv=False, strides=1):\n",
        "        #初始化\n",
        "        super().__init__()\n",
        "        #两个卷积层，内核大小都为3，\n",
        "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
        "                               kernel_size=3, padding=1, stride=strides)\n",
        "        #输入通道为上一层的输出通道\n",
        "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
        "                               kernel_size=3, padding=1)\n",
        "        if use_1x1conv:#如果不使用的话，在应用Relu前，将输入添加到输出；如果使用，通过添加1×1卷积来调整通道和分辨率\n",
        "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
        "                                   kernel_size=1, stride=strides)\n",
        "        else:\n",
        "            self.conv3 = None\n",
        "        #两个批量归一化层\n",
        "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "        if self.conv3:\n",
        "            X = self.conv3(X)\n",
        "        Y += X\n",
        "        return F.relu(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "-5i_NbFU4emF"
      },
      "outputs": [],
      "source": [
        "def resnet18(num_classes, in_channels=1):\n",
        "\n",
        "    def resnet_block(in_channels, out_channels, num_residuals,\n",
        "                     first_block=False):\n",
        "        blk = []\n",
        "        for i in range(num_residuals):\n",
        "            if i == 0 and not first_block:\n",
        "                blk.append(\n",
        "                    Residual(in_channels, out_channels, use_1x1conv=True,\n",
        "                                 strides=2))\n",
        "            else:\n",
        "                blk.append(Residual(out_channels, out_channels))\n",
        "        return nn.Sequential(*blk)\n",
        "\n",
        "    # This model uses a smaller convolution kernel, stride, and padding and\n",
        "    #不可以删掉最大池化层，可能会使梯度消失，使网络的感受野减小\n",
        "    net = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(64), nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "    net.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\n",
        "    net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\n",
        "    net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\n",
        "    net.add_module(\"resnet_block4\", resnet_block(256, 512, 2))\n",
        "    net.add_module(\"global_avg_pool\", nn.AdaptiveAvgPool2d((1, 1)))\n",
        "    net.add_module(\"fc\",\n",
        "                   nn.Sequential(nn.Flatten(), nn.Linear(512, num_classes)))\n",
        "    return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "giWmXSrU4emF"
      },
      "outputs": [],
      "source": [
        "def get_net():\n",
        "    num_classes = 10\n",
        "    net = resnet18(num_classes, 3)\n",
        "    return net\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(reduction=\"none\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-anj7-7q_C7J",
        "outputId": "e08e501e-0a01-4f7b-f900-3f784dd9b3a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d output shape:\t torch.Size([4, 64, 32, 32])\n",
            "BatchNorm2d output shape:\t torch.Size([4, 64, 32, 32])\n",
            "ReLU output shape:\t torch.Size([4, 64, 32, 32])\n",
            "MaxPool2d output shape:\t torch.Size([4, 64, 16, 16])\n",
            "Sequential output shape:\t torch.Size([4, 64, 16, 16])\n",
            "Sequential output shape:\t torch.Size([4, 128, 8, 8])\n",
            "Sequential output shape:\t torch.Size([4, 256, 4, 4])\n",
            "Sequential output shape:\t torch.Size([4, 512, 2, 2])\n",
            "AdaptiveAvgPool2d output shape:\t torch.Size([4, 512, 1, 1])\n",
            "Sequential output shape:\t torch.Size([4, 10])\n"
          ]
        }
      ],
      "source": [
        "X = torch.rand(size=(4, 3, 32, 32))\n",
        "net=get_net()\n",
        "for layer in net:\n",
        "    X = layer(X)\n",
        "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyIvt_FKD0IZ",
        "outputId": "521c6bfc-a249-40be-d34e-91792d29a42a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "swb4MIRTD0sy"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "KoJKIujw6YOS"
      },
      "outputs": [],
      "source": [
        "def try_all_gpus():\n",
        "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\"\"\"\n",
        "    devices = [\n",
        "        torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
        "    return devices if devices else [torch.device('cpu')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR7u-fHK4emF",
        "outputId": "fc794af7-1cfd-4d8f-a974-2139cdaac425"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "Epoch [1/1]，Batch [70/352], Loss: 236.6065, Acc: 0.38\n",
            "Epoch [1/1]，Batch [140/352], Loss: 215.3608, Acc: 0.53\n",
            "Epoch [1/1]，Batch [210/352], Loss: 203.2444, Acc: 0.55\n",
            "Epoch [1/1]，Batch [280/352], Loss: 194.9481, Acc: 0.61\n",
            "Epoch [1/1]，Batch [350/352], Loss: 187.9892, Acc: 0.50\n",
            "Epoch [1/1]，Batch [352/352], Loss: 187.6905, Acc: 0.54\n",
            "Validation Accuracy: 54.86%\n",
            "Fold 2\n",
            "Epoch [1/1]，Batch [70/352], Loss: 152.2674, Acc: 0.62\n",
            "Epoch [1/1]，Batch [140/352], Loss: 147.9587, Acc: 0.62\n",
            "Epoch [1/1]，Batch [210/352], Loss: 143.6009, Acc: 0.63\n",
            "Epoch [1/1]，Batch [280/352], Loss: 142.4070, Acc: 0.71\n",
            "Epoch [1/1]，Batch [350/352], Loss: 140.0634, Acc: 0.65\n",
            "Epoch [1/1]，Batch [352/352], Loss: 139.8185, Acc: 0.67\n",
            "Validation Accuracy: 62.82%\n",
            "Fold 3\n",
            "Epoch [1/1]，Batch [70/352], Loss: 120.9807, Acc: 0.73\n",
            "Epoch [1/1]，Batch [140/352], Loss: 118.9470, Acc: 0.70\n",
            "Epoch [1/1]，Batch [210/352], Loss: 118.0936, Acc: 0.71\n",
            "Epoch [1/1]，Batch [280/352], Loss: 116.8219, Acc: 0.74\n",
            "Epoch [1/1]，Batch [350/352], Loss: 114.8198, Acc: 0.72\n",
            "Epoch [1/1]，Batch [352/352], Loss: 114.6174, Acc: 0.76\n",
            "Validation Accuracy: 65.64%\n",
            "Fold 4\n",
            "Epoch [1/1]，Batch [70/352], Loss: 100.4213, Acc: 0.71\n",
            "Epoch [1/1]，Batch [140/352], Loss: 100.6360, Acc: 0.66\n",
            "Epoch [1/1]，Batch [210/352], Loss: 100.7729, Acc: 0.79\n",
            "Epoch [1/1]，Batch [280/352], Loss: 100.0247, Acc: 0.81\n",
            "Epoch [1/1]，Batch [350/352], Loss: 99.3105, Acc: 0.70\n",
            "Epoch [1/1]，Batch [352/352], Loss: 99.1719, Acc: 0.69\n",
            "Validation Accuracy: 70.44%\n",
            "Fold 5\n",
            "Epoch [1/1]，Batch [70/352], Loss: 85.6041, Acc: 0.80\n",
            "Epoch [1/1]，Batch [140/352], Loss: 87.1567, Acc: 0.69\n",
            "Epoch [1/1]，Batch [210/352], Loss: 86.8141, Acc: 0.80\n",
            "Epoch [1/1]，Batch [280/352], Loss: 86.6959, Acc: 0.68\n",
            "Epoch [1/1]，Batch [350/352], Loss: 86.5258, Acc: 0.77\n",
            "Epoch [1/1]，Batch [352/352], Loss: 86.4126, Acc: 0.72\n",
            "Validation Accuracy: 77.36%\n",
            "Fold 6\n",
            "Epoch [1/1]，Batch [70/352], Loss: 77.8213, Acc: 0.81\n",
            "Epoch [1/1]，Batch [140/352], Loss: 78.9956, Acc: 0.74\n",
            "Epoch [1/1]，Batch [210/352], Loss: 79.3787, Acc: 0.80\n",
            "Epoch [1/1]，Batch [280/352], Loss: 78.9951, Acc: 0.80\n",
            "Epoch [1/1]，Batch [350/352], Loss: 78.6314, Acc: 0.79\n",
            "Epoch [1/1]，Batch [352/352], Loss: 78.5851, Acc: 0.71\n",
            "Validation Accuracy: 78.98%\n",
            "Fold 7\n",
            "Epoch [1/1]，Batch [70/352], Loss: 72.1945, Acc: 0.73\n",
            "Epoch [1/1]，Batch [140/352], Loss: 71.3012, Acc: 0.80\n",
            "Epoch [1/1]，Batch [210/352], Loss: 71.9588, Acc: 0.82\n",
            "Epoch [1/1]，Batch [280/352], Loss: 72.3324, Acc: 0.78\n",
            "Epoch [1/1]，Batch [350/352], Loss: 72.4114, Acc: 0.80\n",
            "Epoch [1/1]，Batch [352/352], Loss: 72.3316, Acc: 0.82\n",
            "Validation Accuracy: 80.56%\n",
            "Fold 8\n",
            "Epoch [1/1]，Batch [70/352], Loss: 65.7794, Acc: 0.85\n",
            "Epoch [1/1]，Batch [140/352], Loss: 66.2955, Acc: 0.84\n",
            "Epoch [1/1]，Batch [210/352], Loss: 66.3754, Acc: 0.81\n",
            "Epoch [1/1]，Batch [280/352], Loss: 65.9924, Acc: 0.79\n",
            "Epoch [1/1]，Batch [350/352], Loss: 65.9759, Acc: 0.87\n",
            "Epoch [1/1]，Batch [352/352], Loss: 65.8573, Acc: 0.86\n",
            "Validation Accuracy: 82.26%\n",
            "Fold 9\n",
            "Epoch [1/1]，Batch [70/352], Loss: 60.5196, Acc: 0.82\n",
            "Epoch [1/1]，Batch [140/352], Loss: 60.7555, Acc: 0.80\n",
            "Epoch [1/1]，Batch [210/352], Loss: 60.9057, Acc: 0.87\n",
            "Epoch [1/1]，Batch [280/352], Loss: 60.6639, Acc: 0.84\n",
            "Epoch [1/1]，Batch [350/352], Loss: 60.3002, Acc: 0.82\n",
            "Epoch [1/1]，Batch [352/352], Loss: 60.2457, Acc: 0.89\n",
            "Validation Accuracy: 83.40%\n",
            "Fold 10\n",
            "Epoch [1/1]，Batch [70/352], Loss: 57.0316, Acc: 0.85\n",
            "Epoch [1/1]，Batch [140/352], Loss: 57.3797, Acc: 0.87\n",
            "Epoch [1/1]，Batch [210/352], Loss: 57.2159, Acc: 0.86\n",
            "Epoch [1/1]，Batch [280/352], Loss: 57.0768, Acc: 0.82\n",
            "Epoch [1/1]，Batch [350/352], Loss: 57.0885, Acc: 0.83\n",
            "Epoch [1/1]，Batch [352/352], Loss: 56.9715, Acc: 0.86\n",
            "Validation Accuracy: 83.48%\n"
          ]
        }
      ],
      "source": [
        "# 训练：\n",
        "device,num_epochs, lr, wd =try_all_gpus(),20, 2e-4, 5e-4\n",
        "lr_period, lr_decay, net = 4, 0.9, get_net()\n",
        "# train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,lr_decay)\n",
        "k_fold(net, criterion, lr_period, lr_decay, lr, wd, trainset,device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader, devices):\n",
        "    \"\"\"\n",
        "    在完整的验证集上评估模型性能\n",
        "\n",
        "    参数:\n",
        "    model (torch.nn.Module): 训练好的模型\n",
        "    testset (torch.utils.data.Dataset): 验证数据集\n",
        "    device (torch.device): 运行设备(CPU或GPU)\n",
        "\n",
        "    返回:\n",
        "    float: 模型在验证集上的性能指标(例如准确率)\n",
        "    \"\"\"\n",
        "    model.eval()  # 设置模型为评估模式\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # test_loader = DataLoader(testset, batch_size=128, shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            if isinstance(data, list):\n",
        "              # Required for BERT fine-tuning (to be covered later)\n",
        "              data = [x.to(devices[0]) for x in data]\n",
        "            else:\n",
        "                data = data.to(devices[0])\n",
        "            target =  target.to(devices[0])\n",
        "            output = model(data)\n",
        "\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Validation Accuracy: {accuracy:.2f}%')\n",
        "    # return accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "RE3M5v5ELoUA"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net=get_net()\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=True, num_workers=2)\n",
        "evaluate(net, test_loader, device)"
      ],
      "metadata": {
        "id": "Tc4ELE8HM2wx",
        "outputId": "651a2fb9-7395-4b7b-fed4-06d88a521b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-9068f76f69d7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-66-259ff698140e>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, test_loader, devices)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "d2l",
      "language": "python",
      "name": "d2l"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}