{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youcancallme/sdu-deeplearning-cifar-10/blob/main/CIFAR-10-v5-changeTrain-numbatch%3D1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDkwnu6X4el-"
      },
      "source": [
        "# 初始化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDKs8U2z4el_"
      },
      "source": [
        "## 本地实现"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuPONzSXfdg1"
      },
      "source": [
        "首先进行的是文件读取"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j01-fgRTfjeR",
        "outputId": "3b86e5cf-47ed-4f73-c0fb-e044e6844b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkP6KD4j4emC"
      },
      "source": [
        "## torchvision实现"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KumQxCz64emC"
      },
      "source": [
        "上面是我自己对数据的处理，其实torchvision提供了对cifar-10数据集的处理，并且提供了及其方便的预处理代码"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cmu5X4aM4emD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6MeWu1R4emD"
      },
      "source": [
        "### 数据增强"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIj2nYmM4emD"
      },
      "source": [
        "图像增广，训练集进行增广，测试时标准化执行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Sw16QZnV4emD"
      },
      "outputs": [],
      "source": [
        "#已经解压的数据集路径\n",
        "#本地\n",
        "# unzip_folder_path='../cifar-10-python'\n",
        "#colab\n",
        "unzip_folder_path= '/content/drive/MyDrive/cifar-10-python'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1c7rN2oL4emD"
      },
      "outputs": [],
      "source": [
        "#训练集\n",
        "transform_train = torchvision.transforms.Compose([\n",
        "    # 在高度和宽度上将图像放大到40像素的正方形\n",
        "    torchvision.transforms.Resize(40),\n",
        "    # 生成一个面积为原始图像面积0.64～1倍的小正方形，\n",
        "    # 然后将其缩放为高度和宽度均为32像素的正方形\n",
        "    torchvision.transforms.RandomResizedCrop(32, scale=(0.64, 1.0),ratio=(1.0, 1.0)),\n",
        "    #以 50% 的概率对输入图像进行水平翻转,用于数据增强。\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    # NumPy 数组转换为 PyTorch Tensor 。\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    # 标准化图像的每个通道 三通道分别归一化，到均值为 0、标准差为 1 的分布。\n",
        "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
        "                                     [0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "#测试集\n",
        "transform_test = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
        "                                     [0.2023, 0.1994, 0.2010])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xymu_dC04emD"
      },
      "outputs": [],
      "source": [
        "#如果不使用数据增广的话，只将数据变为tensor和标准化\n",
        "transform= torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
        "                                     [0.2023, 0.1994, 0.2010])])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cJxK43n64emD"
      },
      "outputs": [],
      "source": [
        "#训练集 train=True加载训练集\n",
        "trainset = torchvision.datasets.CIFAR10(root=unzip_folder_path, train=True,\n",
        "                                        download=False, transform=transform_train)\n",
        "\n",
        "#测试集\n",
        "testset = torchvision.datasets.CIFAR10(root=unzip_folder_path, train=False,\n",
        "                                       download=False, transform=transform_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1DIW8SNS_C7H",
        "outputId": "a4e52add-438f-463f-ecf0-7f30e50d3d1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "image, label = trainset[0]\n",
        "image_size = image.size()\n",
        "image_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6oZQvPX4emD"
      },
      "source": [
        "### 创建数据加载器"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elzBKu_w4emD"
      },
      "source": [
        "DataLoader将数据集转换为可迭代的数据加载器对象。\n",
        "batch_size参数指定每个批次中的样本数量。\n",
        "shuffle=True表示在每个时期(epoch)开始时对数据进行洗牌。\n",
        "num_workers参数指定用于数据加载的线程数\n",
        "但是这里没用到啊，只有在kfold哪里用到了，而且test的还没有进行验证"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff_mSOxK4emE"
      },
      "outputs": [],
      "source": [
        "# #训练集  batch_size=128  shuffle=True打乱数据  num_workers=2使用两个进程加载数据\n",
        "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "#                                           shuffle=True, num_workers=2)\n",
        "\n",
        "# #测试集 batch_size=128  shuffle=False不打乱数据  num_workers=2使用两个进程加载数据\n",
        "# testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "#                                          shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7aMuYZH4emE"
      },
      "source": [
        "## 1折交叉验证"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCXrvNlI4emE"
      },
      "source": [
        "使用KFold类从sklearn.model_selection库中创建了一个1折交叉验证对象。n_splits参数设置为10，表示将数据集划分为10个折（10份），shuffle=True表示在划分前对数据进行洗牌。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Et9cwLFF4emE"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=10, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AcZ0r2nq4emE"
      },
      "outputs": [],
      "source": [
        "# argmax 函数别名定义了一个匿名函数，它接受参数 x，并调用 x.argmax(*args, **kwargs) 方法。\n",
        "# astype 函数别名定义了一个匿名函数，它接受参数 x，并调用 x.type(*args, **kwargs) 方法。\n",
        "# reduce_sum 函数别名定义了一个匿名函数，它接受参数 x，并调用 x.sum(*args, **kwargs) 方法。\n",
        "\n",
        "argmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs)\n",
        "astype = lambda x, *args, **kwargs: x.type(*args, **kwargs)\n",
        "reduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)\n",
        "def accuracy(y_hat, y):\n",
        "    #首先处理y_hat形状，如果 y_hat 的维度大于1且最后一个维度大于1,则说明 y_hat 是一个包含多个类别概率的tensor。\n",
        "    #这种情况下,需要使用 argmax 函数找出每个样本预测概率最高的类别索引,赋值给 y_hat。\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = argmax(y_hat, axis=1)\n",
        "  #使用astype函数将y_hat的数据类型转换为和y相同的类型,方便比较\n",
        "  #比较是否相等，如果相等就得到布尔类型的tensor\n",
        "    cmp = astype(y_hat, y.dtype) == y\n",
        "  #使用 reduce_sum 函数统计 cmp 中为True的元素个数,得到预测正确的样本数\n",
        "    return float(reduce_sum(astype(cmp, y.dtype)))\n",
        "# def accuracy(y_hat, y):\n",
        "#     \"\"\"Compute the number of correct predictions.\"\"\"\n",
        "#     if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "#         y_hat = y_hat.argmax(dim=1)\n",
        "#     cmp = y_hat.type(y.dtype) == y\n",
        "#     return float(cmp.type(y.dtype).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "U5Pzk1fA4emE"
      },
      "outputs": [],
      "source": [
        "def train_batch(net, X, y, loss, trainer, devices):\n",
        "    # 转移到一个device上\n",
        "    if isinstance(X, list):\n",
        "        # Required for BERT fine-tuning (to be covered later)\n",
        "        X = [x.to(devices[0]) for x in X]\n",
        "    else:\n",
        "        X = X.to(devices[0])\n",
        "    y = y.to(devices[0])\n",
        "    #训练\n",
        "    net.train()\n",
        "    #梯度为0\n",
        "    trainer.zero_grad()\n",
        "    #前向传播\n",
        "    pred = net(X)\n",
        "    #计算损失\n",
        "    l = loss(pred, y)\n",
        "    #反向传播更新参数\n",
        "    l.sum().backward()\n",
        "    trainer.step()\n",
        "\n",
        "    #本批次的损失和准确度\n",
        "    train_loss_sum = l.sum()\n",
        "    train_acc_sum = accuracy(pred, y)\n",
        "    return train_loss_sum, train_acc_sum\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "BJlvc79FDkIw"
      },
      "outputs": [],
      "source": [
        "def k_fold(net, criterion, lr_period, lr_decay, lr, wd, trainset, devices, num_epochs=1, batch_size=128):\n",
        "    # 使用 KFold 进行 10 折交叉验证，shuffle=True 表示打乱数据集\n",
        "    kfold = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "    # for epoch in range(num_epochs):\n",
        "        # 一折交叉验证\n",
        "    for fold, (train_indices, val_indices) in enumerate(kfold.split(trainset)):\n",
        "        print(f'Fold {fold+1}')\n",
        "\n",
        "        trainset_fold = torch.utils.data.Subset(trainset, train_indices)  # 获取当前折的训练集\n",
        "        valset_fold = torch.utils.data.Subset(trainset, val_indices)  # 获取当前折的验证集\n",
        "\n",
        "        #当前折训练数据集\n",
        "        trainloader_fold = torch.utils.data.DataLoader(trainset_fold, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "        #当前折验证数据集\n",
        "        valloader_fold = torch.utils.data.DataLoader(valset_fold, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "        # 为每一折创建一个新的网络实例\n",
        "        model = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
        "\n",
        "          # sgd优化器\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
        "        #学习率调度器，\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_period, lr_decay)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "\n",
        "            #running_loss 用于记录整个训练过程中的累积损失值。\n",
        "            running_loss = 0.0\n",
        "            model.train()\n",
        "\n",
        "            #循环训练集的特征和标签\n",
        "            for i, (inputs, labels) in enumerate(trainloader_fold):\n",
        "              #计算每个批次的损失和返回预测正确的样本数，\n",
        "              #net 特征 标签 损失函数 sgd优化器 设备\n",
        "                loss, acc = train_batch(model, inputs, labels, criterion, optimizer, devices)\n",
        "                #用正确的样本数/当前batch的总样本数即可\n",
        "                Acc=float(acc) / labels.shape[0]\n",
        "\n",
        "              #将当前批次的损失值 loss 加到 running_loss 变量中。\n",
        "                running_loss += loss.item()\n",
        "              #检查当前批次的索引是否为训练数据批次总数的 1/5 倍,或者是否为最后一个批次。\n",
        "                if (i + 1) % (len(trainloader_fold) // 5) == 0 or i == len(trainloader_fold) - 1:\n",
        "                  #当前batch的索引和总batch数量，当前的平均损失，当前的准确率\n",
        "                    print(f'Epoch [{epoch+1}/{num_epochs}]，Batch [{i+1}/{len(trainloader_fold)}], Loss: {running_loss / (i + 1):.4f}, Acc: {Acc:.2f}')\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            for inputs, labels in valloader_fold:\n",
        "                inputs = inputs.to(devices[0])\n",
        "                labels = labels.to(devices[0])\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "            print(f'Validation Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "      # 绘制损失、训练集正确率和验证集正确率\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(train_losses)\n",
        "    plt.title('Training Loss')\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(train_accs)\n",
        "    plt.title('Training Accuracy')\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Accuracy')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(val_accs)\n",
        "    plt.title('Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2swg6sg4emE"
      },
      "source": [
        "## ResNet模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc_FCUk-4emF"
      },
      "source": [
        "残差块"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wuZxJ8Zq4emF"
      },
      "outputs": [],
      "source": [
        "from torch.nn import functional as F\n",
        "#画图表示\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, input_channels, num_channels,\n",
        "                 use_1x1conv=False, strides=1):\n",
        "        #初始化\n",
        "        super().__init__()\n",
        "        #两个卷积层，内核大小都为3，\n",
        "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
        "                               kernel_size=3, padding=1, stride=strides)\n",
        "        #输入通道为上一层的输出通道\n",
        "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
        "                               kernel_size=3, padding=1)\n",
        "        if use_1x1conv:#如果不使用的话，在应用Relu前，将输入添加到输出；如果使用，通过添加1×1卷积来调整通道和分辨率\n",
        "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
        "                                   kernel_size=1, stride=strides)\n",
        "        else:\n",
        "            self.conv3 = None\n",
        "        #两个批量归一化层\n",
        "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "        if self.conv3:\n",
        "            X = self.conv3(X)\n",
        "        Y += X\n",
        "        return F.relu(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-5i_NbFU4emF"
      },
      "outputs": [],
      "source": [
        "def resnet18(num_classes, in_channels=1):\n",
        "\n",
        "    def resnet_block(in_channels, out_channels, num_residuals,\n",
        "                     first_block=False):\n",
        "        blk = []\n",
        "        for i in range(num_residuals):\n",
        "            if i == 0 and not first_block:\n",
        "                blk.append(\n",
        "                    Residual(in_channels, out_channels, use_1x1conv=True,\n",
        "                                 strides=2))\n",
        "            else:\n",
        "                blk.append(Residual(out_channels, out_channels))\n",
        "        return nn.Sequential(*blk)\n",
        "\n",
        "    # This model uses a smaller convolution kernel, stride, and padding and\n",
        "    #不可以删掉最大池化层，可能会使梯度消失，使网络的感受野减小\n",
        "    net = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(64), nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "    net.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\n",
        "    net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\n",
        "    net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\n",
        "    net.add_module(\"resnet_block4\", resnet_block(256, 512, 2))\n",
        "    net.add_module(\"global_avg_pool\", nn.AdaptiveAvgPool2d((1, 1)))\n",
        "    net.add_module(\"fc\",\n",
        "                   nn.Sequential(nn.Flatten(), nn.Linear(512, num_classes)))\n",
        "    return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "giWmXSrU4emF"
      },
      "outputs": [],
      "source": [
        "def get_net():\n",
        "    num_classes = 10\n",
        "    net = resnet18(num_classes, 3)\n",
        "    return net\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(reduction=\"none\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-anj7-7q_C7J",
        "outputId": "32e66ac1-4880-40b3-a9fe-b5d3ddbc2d5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d output shape:\t torch.Size([4, 64, 32, 32])\n",
            "BatchNorm2d output shape:\t torch.Size([4, 64, 32, 32])\n",
            "ReLU output shape:\t torch.Size([4, 64, 32, 32])\n",
            "MaxPool2d output shape:\t torch.Size([4, 64, 16, 16])\n",
            "Sequential output shape:\t torch.Size([4, 64, 16, 16])\n",
            "Sequential output shape:\t torch.Size([4, 128, 8, 8])\n",
            "Sequential output shape:\t torch.Size([4, 256, 4, 4])\n",
            "Sequential output shape:\t torch.Size([4, 512, 2, 2])\n",
            "AdaptiveAvgPool2d output shape:\t torch.Size([4, 512, 1, 1])\n",
            "Sequential output shape:\t torch.Size([4, 10])\n"
          ]
        }
      ],
      "source": [
        "X = torch.rand(size=(4, 3, 32, 32))\n",
        "net=get_net()\n",
        "for layer in net:\n",
        "    X = layer(X)\n",
        "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "id": "WyIvt_FKD0IZ",
        "outputId": "da9b4041-05b3-4db8-fdf2-908638d74b96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "swb4MIRTD0sy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KoJKIujw6YOS"
      },
      "outputs": [],
      "source": [
        "def try_all_gpus():\n",
        "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\"\"\"\n",
        "    devices = [\n",
        "        torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
        "    return devices if devices else [torch.device('cpu')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iR7u-fHK4emF",
        "outputId": "c3741160-d2f2-42de-dd50-13611feb7e4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "Epoch [1/1]，Batch [70/352], Loss: 243.8685, Acc: 0.35\n",
            "Epoch [1/1]，Batch [140/352], Loss: 223.1347, Acc: 0.36\n",
            "Epoch [1/1]，Batch [210/352], Loss: 210.9637, Acc: 0.44\n",
            "Epoch [1/1]，Batch [280/352], Loss: 202.3430, Acc: 0.50\n",
            "Epoch [1/1]，Batch [350/352], Loss: 194.6184, Acc: 0.55\n",
            "Epoch [1/1]，Batch [352/352], Loss: 194.1608, Acc: 0.58\n",
            "Validation Accuracy: 52.24%\n",
            "Fold 2\n",
            "Epoch [1/1]，Batch [70/352], Loss: 152.5094, Acc: 0.57\n",
            "Epoch [1/1]，Batch [140/352], Loss: 150.3627, Acc: 0.61\n",
            "Epoch [1/1]，Batch [210/352], Loss: 148.2907, Acc: 0.58\n",
            "Epoch [1/1]，Batch [280/352], Loss: 144.9788, Acc: 0.62\n",
            "Epoch [1/1]，Batch [350/352], Loss: 142.4782, Acc: 0.59\n",
            "Epoch [1/1]，Batch [352/352], Loss: 142.1794, Acc: 0.67\n",
            "Validation Accuracy: 64.86%\n",
            "Fold 3\n",
            "Epoch [1/1]，Batch [70/352], Loss: 123.7064, Acc: 0.67\n",
            "Epoch [1/1]，Batch [140/352], Loss: 121.7337, Acc: 0.66\n",
            "Epoch [1/1]，Batch [210/352], Loss: 120.1795, Acc: 0.66\n",
            "Epoch [1/1]，Batch [280/352], Loss: 119.2716, Acc: 0.66\n",
            "Epoch [1/1]，Batch [350/352], Loss: 117.4753, Acc: 0.69\n",
            "Epoch [1/1]，Batch [352/352], Loss: 117.3001, Acc: 0.75\n",
            "Validation Accuracy: 65.00%\n",
            "Fold 4\n",
            "Epoch [1/1]，Batch [70/352], Loss: 103.6418, Acc: 0.70\n",
            "Epoch [1/1]，Batch [140/352], Loss: 102.8847, Acc: 0.70\n",
            "Epoch [1/1]，Batch [210/352], Loss: 101.8686, Acc: 0.73\n",
            "Epoch [1/1]，Batch [280/352], Loss: 101.1232, Acc: 0.69\n",
            "Epoch [1/1]，Batch [350/352], Loss: 99.9935, Acc: 0.73\n",
            "Epoch [1/1]，Batch [352/352], Loss: 99.8063, Acc: 0.76\n",
            "Validation Accuracy: 67.74%\n",
            "Fold 5\n",
            "Epoch [1/1]，Batch [70/352], Loss: 86.0704, Acc: 0.73\n",
            "Epoch [1/1]，Batch [140/352], Loss: 89.0023, Acc: 0.77\n",
            "Epoch [1/1]，Batch [210/352], Loss: 87.6614, Acc: 0.76\n",
            "Epoch [1/1]，Batch [280/352], Loss: 87.4280, Acc: 0.73\n",
            "Epoch [1/1]，Batch [350/352], Loss: 86.3696, Acc: 0.80\n",
            "Epoch [1/1]，Batch [352/352], Loss: 86.1900, Acc: 0.78\n",
            "Validation Accuracy: 77.06%\n",
            "Fold 6\n",
            "Epoch [1/1]，Batch [70/352], Loss: 76.6299, Acc: 0.85\n",
            "Epoch [1/1]，Batch [140/352], Loss: 77.6921, Acc: 0.77\n",
            "Epoch [1/1]，Batch [210/352], Loss: 78.3178, Acc: 0.81\n",
            "Epoch [1/1]，Batch [280/352], Loss: 78.7367, Acc: 0.80\n",
            "Epoch [1/1]，Batch [350/352], Loss: 78.6608, Acc: 0.84\n",
            "Epoch [1/1]，Batch [352/352], Loss: 78.5423, Acc: 0.83\n",
            "Validation Accuracy: 75.58%\n",
            "Fold 7\n",
            "Epoch [1/1]，Batch [70/352], Loss: 69.4634, Acc: 0.77\n",
            "Epoch [1/1]，Batch [140/352], Loss: 71.4218, Acc: 0.84\n",
            "Epoch [1/1]，Batch [210/352], Loss: 72.6303, Acc: 0.85\n",
            "Epoch [1/1]，Batch [280/352], Loss: 72.9480, Acc: 0.80\n",
            "Epoch [1/1]，Batch [350/352], Loss: 72.9485, Acc: 0.78\n",
            "Epoch [1/1]，Batch [352/352], Loss: 72.8211, Acc: 0.83\n",
            "Validation Accuracy: 78.12%\n",
            "Fold 8\n",
            "Epoch [1/1]，Batch [70/352], Loss: 65.0044, Acc: 0.84\n",
            "Epoch [1/1]，Batch [140/352], Loss: 65.3850, Acc: 0.83\n",
            "Epoch [1/1]，Batch [210/352], Loss: 66.5634, Acc: 0.80\n",
            "Epoch [1/1]，Batch [280/352], Loss: 66.6368, Acc: 0.77\n",
            "Epoch [1/1]，Batch [350/352], Loss: 66.4095, Acc: 0.85\n",
            "Epoch [1/1]，Batch [352/352], Loss: 66.3829, Acc: 0.81\n",
            "Validation Accuracy: 80.86%\n",
            "Fold 9\n",
            "Epoch [1/1]，Batch [70/352], Loss: 59.6791, Acc: 0.77\n",
            "Epoch [1/1]，Batch [140/352], Loss: 59.0568, Acc: 0.80\n",
            "Epoch [1/1]，Batch [210/352], Loss: 60.6765, Acc: 0.84\n",
            "Epoch [1/1]，Batch [280/352], Loss: 60.7557, Acc: 0.84\n",
            "Epoch [1/1]，Batch [350/352], Loss: 61.4884, Acc: 0.82\n",
            "Epoch [1/1]，Batch [352/352], Loss: 61.4531, Acc: 0.86\n",
            "Validation Accuracy: 81.94%\n",
            "Fold 10\n",
            "Epoch [1/1]，Batch [70/352], Loss: 53.0346, Acc: 0.84\n",
            "Epoch [1/1]，Batch [140/352], Loss: 55.1655, Acc: 0.86\n",
            "Epoch [1/1]，Batch [210/352], Loss: 55.7563, Acc: 0.84\n",
            "Epoch [1/1]，Batch [280/352], Loss: 56.3363, Acc: 0.88\n",
            "Epoch [1/1]，Batch [350/352], Loss: 56.4045, Acc: 0.88\n",
            "Epoch [1/1]，Batch [352/352], Loss: 56.4050, Acc: 0.81\n",
            "Validation Accuracy: 81.92%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_losses' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e95eff697356>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlr_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,lr_decay)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mk_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-863aa622b675>\u001b[0m in \u001b[0;36mk_fold\u001b[0;34m(net, criterion, lr_period, lr_decay, lr, wd, trainset, devices, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 使用示例\n",
        "device,num_epochs, lr, wd =try_all_gpus(),20, 2e-4, 5e-4\n",
        "lr_period, lr_decay, net = 4, 0.9, get_net()\n",
        "# train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,lr_decay)\n",
        "k_fold(net, criterion, lr_period, lr_decay, lr, wd, trainset,device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "d2l",
      "language": "python",
      "name": "d2l"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}